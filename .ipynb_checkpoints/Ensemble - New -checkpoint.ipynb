{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4 (default, Aug 13 2019, 15:17:50) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from  collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = 'raw_ecg_processed_lead_new/'\n",
    "\n",
    "\n",
    "ScanDictRawECG = {}\n",
    "for scanIdx, scanId in enumerate( os.listdir(baseDir)):\n",
    "    print(scanIdx)\n",
    "    if scanId not in ScanDictRawECG:\n",
    "        ScanDictRawECG[scanId] = []\n",
    "    tlist = open(os.path.join(baseDir, scanId) ).read().split('\\n')\n",
    "    for eentry in tlist[250*5 : -250*5]:        \n",
    "        eentry = eentry.split('\\t')\n",
    "        if len(eentry) >= 12:\n",
    "            eentry = [ int(ee) for ee in eentry[0:12] ]\n",
    "            ScanDictRawECG[scanId].append(eentry)        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLI0200@5@73201718243468764', 'NORMAL', 'Normal ECG']\n"
     ]
    }
   ],
   "source": [
    "resDir='classifier_data_set.txt'\n",
    "# Loading Scands Ids with (AR)Rhythm Type\n",
    "\n",
    "list_of_ecg_scans_with_rhythm_type = {}\n",
    "for erecord in open('classifier_data_set.txt').readlines():\n",
    "    erecord = erecord.strip('\\n,').split(',')[0:3] # Col1: ScanId, Col2: Normal/Abnormal Col3: Specific Type of DysRhythm (if any)\n",
    "    list_of_ecg_scans_with_rhythm_type[erecord[0]] = erecord\n",
    "\n",
    "print(list_of_ecg_scans_with_rhythm_type['CLI0200@5@73201718243468764'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noData = 0 \n",
    "RawEcgScan    = []\n",
    "LeadIIEcgScan = []\n",
    "scanTypesInt  = []\n",
    "for eScanId in set( ScanDictLeadII.keys()  ).intersection ( set( ScanDictRawECG.keys() ) ) :\n",
    "    if len(ScanDictRawECG[eScanId]) == 0:\n",
    "        noData += 1\n",
    "    RawEcgScan.append    ( ScanDictRawECG[eScanId] )\n",
    "    LeadIIEcgScan.append ( ScanDictLeadII[eScanId] )\n",
    "    if list_of_ecg_scans_with_rhythm_type[eScanId][1] == 'NORMAL':\n",
    "        scanTypesInt.append(0)\n",
    "    else:\n",
    "        scanTypesInt.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_RawECG       = np.array( RawEcgScan )\n",
    "X_LeadII       = np.array( LeadIIEcgScan)\n",
    "raw_ecg_scan_length = 1250\n",
    "lead_2_scan_length  = 10\n",
    "X_RawECG_pad = sequence.pad_sequences(X_RawECG, maxlen=raw_ecg_scan_length)\n",
    "X_LeadII_pad = sequence.pad_sequences(X_LeadII, maxlen=lead_2_scan_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1094, 1250, 12), (1094, 10, 15))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_RawECG_pad.shape, X_LeadII_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((875, 1250, 12),\n",
       " (219, 1250, 12),\n",
       " (875, 10, 15),\n",
       " (219, 10, 15),\n",
       " (875,),\n",
       " (219,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                    \n",
    "Y = np.array(scanTypesInt)\n",
    "trainValPercent = 0.8\n",
    "totSamples = X_RawECG.shape[0]\n",
    "shuffleIdxs = list (range(0,totSamples))\n",
    "random.shuffle( shuffleIdxs  )\n",
    "X_RawECG_train = X_RawECG_pad[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ],  ]\n",
    "X_RawECG_test  = X_RawECG_pad[ shuffleIdxs[ int(trainValPercent * totSamples) :   ],  ]\n",
    "X_LeadII_train = X_LeadII_pad[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ],  ]\n",
    "X_LeadII_test  = X_LeadII_pad[ shuffleIdxs[ int(trainValPercent * totSamples) :   ],  ]\n",
    "\n",
    "\n",
    "Y_train = Y[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ]   ]\n",
    "Y_test  = Y[ shuffleIdxs[ int(trainValPercent * totSamples) :   ]   ]\n",
    "\n",
    "\n",
    "X_RawECG_train.shape, X_RawECG_test.shape,X_LeadII_train.shape, X_LeadII_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawecg_lead2_convseparable( lead_2_input_data, raw_ecg_input_data):\n",
    "    \n",
    "    lead_2_input_data_batchnormalized  = layers.BatchNormalization()(lead_2_input_data)\n",
    "    raw_ecg_input_data_batchnormalized = layers.BatchNormalization()(raw_ecg_input_data)\n",
    "\n",
    "    convBase = layers.Conv1D(32, 50,activation='relu')(raw_ecg_input_data_batchnormalized)\n",
    "    convBase = layers.BatchNormalization()(convBase)\n",
    "    convBase = layers.MaxPooling1D((5))(convBase)\n",
    "\n",
    "    convBase = layers.Conv1D(64, 10,activation='relu')(convBase)\n",
    "    convBase = layers.BatchNormalization()(convBase)\n",
    "    convBase = layers.MaxPooling1D((5))(convBase)\n",
    "\n",
    "    convBase = layers.Conv1D(128, 5,activation='relu')(convBase)\n",
    "    convBase = layers.BatchNormalization()(convBase)\n",
    "    convBase = layers.MaxPooling1D((5))(convBase)\n",
    "\n",
    "\n",
    "    separableBase = layers.SeparableConv1D(32, 50,activation='relu')(raw_ecg_input_data_batchnormalized)\n",
    "    separableBase = layers.BatchNormalization()(separableBase)\n",
    "    separableBase = layers.MaxPooling1D((5))(separableBase)\n",
    "\n",
    "    separableBase = layers.SeparableConv1D(64, 10,activation='relu')(separableBase)\n",
    "    separableBase = layers.BatchNormalization()(separableBase)\n",
    "    separableBase = layers.MaxPooling1D((5))(separableBase)\n",
    "\n",
    "    separableBase = layers.SeparableConv1D(128, 5,activation='relu')(separableBase)\n",
    "    separableBase = layers.BatchNormalization()(separableBase)\n",
    "    separableBase = layers.MaxPooling1D((5))(separableBase)\n",
    "\n",
    "    concatenated  = layers.concatenate([convBase, separableBase], axis=-1)\n",
    "    raw_ecg_branch= layers.Flatten()(concatenated)\n",
    "\n",
    "\n",
    "    lead_2_brach = layers.Conv1D(32,  5, activation='relu')(lead_2_input_data_batchnormalized)\n",
    "    lead_2_brach = layers.Conv1D(64,  3, activation='relu')(lead_2_brach)\n",
    "    lead_2_brach = layers.Conv1D(128, 1, activation='relu')(lead_2_brach)\n",
    "    lead_2_brach = layers.Flatten()(lead_2_brach)\n",
    "\n",
    "    raw_ecg_concat = layers.concatenate([raw_ecg_branch, lead_2_brach], axis=-1)\n",
    "\n",
    "    raw_ecg_concat = layers.Dense(128, activation='relu')(raw_ecg_concat)\n",
    "\n",
    "    raw_ecg_concat = layers.Dropout(0.25)((raw_ecg_concat))\n",
    "\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(raw_ecg_concat)\n",
    "\n",
    "    model = Model(inputs=[lead_2_input_data, raw_ecg_input_data], outputs=predictions)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseModel_SeparableConvGRUWithStrides(model_input):\n",
    "\t\n",
    "\n",
    "\tx = layers.BatchNormalization()(model_input)\n",
    "\n",
    "\tx = layers.SeparableConv1D(32, 50,activation='relu', strides=2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.SeparableConv1D(64, 10,activation='relu', strides=2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.SeparableConv1D(128, 5,activation='relu', strides=2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\n",
    "\tx = layers.GRU( 32, dropout=0.1, recurrent_dropout=0.5,  return_sequences=True)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.GRU( 64, dropout=0.1, recurrent_dropout=0.5,  return_sequences=True)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.GRU( 128, dropout=0.1, recurrent_dropout=0.5)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\n",
    "\tx = layers.Dense(128, activation='relu')(x)\n",
    "\tx = layers.Dropout(0.25)(x)\n",
    "\n",
    "\tpredictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "\tmodel = Model(inputs=model_input, outputs=predictions)\n",
    "\n",
    "\treturn ( model )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseModel_ConvGRUWithStrides(model_input):\n",
    "\n",
    "\n",
    "\tx = layers.BatchNormalization()(model_input)\n",
    "\n",
    "\tx = layers.Conv1D(32, 50,activation='relu', strides=2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\t\n",
    "\tx = layers.Conv1D(64, 10,activation='relu', strides=2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.Conv1D(128, 5,activation='relu', strides=2)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\t\n",
    "\tx = layers.GRU( 32, dropout=0.1, recurrent_dropout=0.5,  return_sequences=True)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.GRU( 64, dropout=0.1, recurrent_dropout=0.5,  return_sequences=True)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.GRU( 128, dropout=0.1, recurrent_dropout=0.5)(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\n",
    "\tx = layers.Dense(128, activation='relu')(x)\n",
    "\tx = layers.Dropout(0.25)(x)\n",
    "\n",
    "\tpredictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "\tmodel = Model(inputs=model_input, outputs=predictions)\n",
    "\n",
    "\treturn ( model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convSeparable(model_input):\n",
    "    \n",
    "    x = layers.BatchNormalization()(model_input)\n",
    "\n",
    "    \n",
    "    convBase = layers.Conv1D(32, 50,activation='relu')(x)\n",
    "    convBase = layers.BatchNormalization()(convBase)\n",
    "    convBase = layers.MaxPooling1D((5))(convBase)\n",
    "\n",
    "    convBase = layers.Conv1D(64, 10,activation='relu')(convBase)\n",
    "    convBase = layers.BatchNormalization()(convBase)\n",
    "    convBase = layers.MaxPooling1D((5))(convBase)\n",
    "\n",
    "    convBase = layers.Conv1D(128, 5,activation='relu')(convBase)\n",
    "    convBase = layers.BatchNormalization()(convBase)\n",
    "    convBase = layers.MaxPooling1D((5))(convBase)\n",
    "    \n",
    "    \n",
    "    separableBase = layers.SeparableConv1D(32, 50,activation='relu')(x)\n",
    "    separableBase = layers.BatchNormalization()(separableBase)\n",
    "    separableBase = layers.MaxPooling1D((5))(separableBase)\n",
    "\n",
    "    separableBase = layers.SeparableConv1D(64, 10,activation='relu')(separableBase)\n",
    "    separableBase = layers.BatchNormalization()(separableBase)\n",
    "    separableBase = layers.MaxPooling1D((5))(separableBase)\n",
    "\n",
    "    separableBase = layers.SeparableConv1D(128, 5,activation='relu')(separableBase)\n",
    "    separableBase = layers.BatchNormalization()(separableBase)\n",
    "    separableBase = layers.MaxPooling1D((5))(separableBase)\n",
    "    \n",
    "    concatenated  = layers.concatenate([convBase, separableBase], axis=-1)\n",
    "    concatenated  = layers.Flatten()(concatenated)\n",
    "    concatenated  = layers.Dropout(0.25)(concatenated)\n",
    "\n",
    "    denseLayer    = layers.Dense(128, activation='relu')(concatenated)\n",
    "    denseLayer    = layers.Dropout(0.25)(denseLayer)\n",
    "    predictions   = layers.Dense(1, activation='sigmoid')(denseLayer)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=predictions)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseModel_Separable1D(model_input):\n",
    "\n",
    "\tx = layers.BatchNormalization()(model_input)\n",
    "\n",
    "\tx = layers.SeparableConv1D(32, 50,activation='relu')(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.MaxPool1D((5))(x)\n",
    "\n",
    "\tx = layers.SeparableConv1D(64, 10,activation='relu')(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.MaxPool1D((5))(x)\n",
    "\t\n",
    "\tx = layers.SeparableConv1D(128, 5,activation='relu')(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.MaxPool1D((5))(x)\n",
    "\n",
    "\tx = layers.Flatten()(x)\n",
    "\tx = layers.Dropout(0.25)(x)\n",
    "\n",
    "\tx = layers.Dense(128, activation='relu')(x)\n",
    "\tx = layers.Dropout(0.25)(x)\n",
    "\n",
    "\tpredictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "\tmodel = Model(inputs=model_input, outputs=predictions)\n",
    "    \n",
    "\treturn (model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseModel_Conv1D(model_input):\n",
    "\n",
    "\tx = layers.BatchNormalization()(model_input)\n",
    "\n",
    "\tx = layers.Conv1D(32, 50,activation='relu')(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.MaxPool1D((5))(x)\n",
    "\n",
    "\tx = layers.Conv1D(64, 10,activation='relu')(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.MaxPool1D((5))(x)\n",
    "\t\n",
    "\tx = layers.Conv1D(128, 5,activation='relu')(x)\n",
    "\tx = layers.BatchNormalization()(x)\n",
    "\tx = layers.MaxPool1D((5))(x)\n",
    "\n",
    "\tx = layers.Flatten()(x)\n",
    "\tx = layers.Dropout(0.25)(x)\n",
    "\n",
    "\tx = layers.Dense(128, activation='relu')(x)\n",
    "\tx = layers.Dropout(0.25)(x)\n",
    "\n",
    "\tpredictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "\tmodel = Model(inputs=model_input, outputs=predictions)\n",
    "\n",
    "\treturn (model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead2Model(model_input):\n",
    "    \n",
    "    lead_2_input_data_batchnormalized  = layers.BatchNormalization()(model_input)\n",
    "    \n",
    "    lead_2_branch = layers.Conv1D(32,  5, activation='relu')(lead_2_input_data_batchnormalized)\n",
    "    lead_2_branch = layers.Conv1D(64,  3, activation='relu')(lead_2_branch)\n",
    "    lead_2_branch = layers.Conv1D(128, 1, activation='relu')(lead_2_branch)\n",
    "    lead_2_branch = layers.Flatten()(lead_2_branch)\n",
    "    \n",
    "    predictions = layers.Dense(1, activation='sigmoid')(lead_2_branch)\n",
    "    model = Model(inputs=model_input, outputs=predictions)\n",
    "    \n",
    "    return model;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 175 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 0.9000 - acc: 0.6943 - val_loss: 0.4487 - val_acc: 0.8057\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s 162us/step - loss: 0.5607 - acc: 0.7286 - val_loss: 0.3999 - val_acc: 0.8400\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.5207 - acc: 0.7643 - val_loss: 0.3891 - val_acc: 0.8457\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.5170 - acc: 0.7657 - val_loss: 0.3878 - val_acc: 0.8400\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s 224us/step - loss: 0.4792 - acc: 0.7843 - val_loss: 0.3840 - val_acc: 0.8171\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.5038 - acc: 0.7971 - val_loss: 0.3889 - val_acc: 0.7886\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.4781 - acc: 0.7943 - val_loss: 0.3910 - val_acc: 0.7829\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.5714 - acc: 0.7914 - val_loss: 0.3931 - val_acc: 0.7600\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s 253us/step - loss: 0.5243 - acc: 0.7914 - val_loss: 0.3943 - val_acc: 0.7657\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s 238us/step - loss: 0.5027 - acc: 0.8043 - val_loss: 0.3871 - val_acc: 0.7600\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s 256us/step - loss: 0.4952 - acc: 0.8157 - val_loss: 0.3874 - val_acc: 0.7600\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s 276us/step - loss: 0.4586 - acc: 0.7914 - val_loss: 0.3894 - val_acc: 0.7714\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s 279us/step - loss: 0.4536 - acc: 0.8143 - val_loss: 0.4605 - val_acc: 0.7886\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s 306us/step - loss: 0.4935 - acc: 0.8071 - val_loss: 0.4616 - val_acc: 0.7714\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s 297us/step - loss: 0.4292 - acc: 0.8114 - val_loss: 0.4540 - val_acc: 0.8057\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s 282us/step - loss: 0.4235 - acc: 0.8057 - val_loss: 0.4556 - val_acc: 0.7886\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s 283us/step - loss: 0.4455 - acc: 0.8086 - val_loss: 0.4598 - val_acc: 0.7657\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s 295us/step - loss: 0.4690 - acc: 0.8100 - val_loss: 0.4545 - val_acc: 0.7886\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s 312us/step - loss: 0.4190 - acc: 0.8143 - val_loss: 0.4537 - val_acc: 0.7886\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s 255us/step - loss: 0.4908 - acc: 0.8029 - val_loss: 0.4597 - val_acc: 0.7886\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s 241us/step - loss: 0.4427 - acc: 0.8186 - val_loss: 0.4551 - val_acc: 0.7886\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s 239us/step - loss: 0.4545 - acc: 0.8014 - val_loss: 0.4597 - val_acc: 0.7657\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s 235us/step - loss: 0.4350 - acc: 0.8171 - val_loss: 0.4476 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s 221us/step - loss: 0.4281 - acc: 0.8286 - val_loss: 0.4561 - val_acc: 0.7600\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.4277 - acc: 0.8043 - val_loss: 0.4495 - val_acc: 0.7657\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s 271us/step - loss: 0.4026 - acc: 0.8329 - val_loss: 0.4569 - val_acc: 0.7714\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s 247us/step - loss: 0.4028 - acc: 0.8229 - val_loss: 0.4524 - val_acc: 0.7829\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s 248us/step - loss: 0.4407 - acc: 0.8200 - val_loss: 0.4521 - val_acc: 0.8057\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s 233us/step - loss: 0.3933 - acc: 0.8186 - val_loss: 0.4557 - val_acc: 0.7943\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s 255us/step - loss: 0.3979 - acc: 0.8300 - val_loss: 0.4555 - val_acc: 0.7771\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s 270us/step - loss: 0.4309 - acc: 0.8229 - val_loss: 0.4458 - val_acc: 0.8114\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s 234us/step - loss: 0.4151 - acc: 0.8229 - val_loss: 0.4526 - val_acc: 0.7771\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s 255us/step - loss: 0.3907 - acc: 0.8114 - val_loss: 0.4451 - val_acc: 0.8171\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s 277us/step - loss: 0.3897 - acc: 0.8286 - val_loss: 0.4480 - val_acc: 0.8114\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s 294us/step - loss: 0.4141 - acc: 0.8314 - val_loss: 0.4455 - val_acc: 0.8229\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s 261us/step - loss: 0.3902 - acc: 0.8214 - val_loss: 0.4431 - val_acc: 0.8229\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s 312us/step - loss: 0.4047 - acc: 0.8143 - val_loss: 0.4606 - val_acc: 0.7657\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s 268us/step - loss: 0.4146 - acc: 0.8100 - val_loss: 0.4483 - val_acc: 0.8171\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s 266us/step - loss: 0.3976 - acc: 0.8386 - val_loss: 0.4458 - val_acc: 0.8229\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s 259us/step - loss: 0.3856 - acc: 0.8257 - val_loss: 0.4521 - val_acc: 0.8229\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s 255us/step - loss: 0.4152 - acc: 0.8357 - val_loss: 0.4589 - val_acc: 0.7771\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s 260us/step - loss: 0.3870 - acc: 0.8286 - val_loss: 0.4569 - val_acc: 0.7829\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s 245us/step - loss: 0.3775 - acc: 0.8257 - val_loss: 0.4520 - val_acc: 0.8286\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s 242us/step - loss: 0.3670 - acc: 0.8443 - val_loss: 0.4572 - val_acc: 0.8057\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s 246us/step - loss: 0.4163 - acc: 0.8371 - val_loss: 0.4493 - val_acc: 0.8229\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s 234us/step - loss: 0.3704 - acc: 0.8300 - val_loss: 0.4490 - val_acc: 0.8286\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s 238us/step - loss: 0.3846 - acc: 0.8271 - val_loss: 0.4491 - val_acc: 0.8229\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s 256us/step - loss: 0.3926 - acc: 0.8343 - val_loss: 0.4434 - val_acc: 0.8229\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s 337us/step - loss: 0.3836 - acc: 0.8386 - val_loss: 0.4542 - val_acc: 0.8229\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s 290us/step - loss: 0.3822 - acc: 0.8429 - val_loss: 0.4486 - val_acc: 0.8171\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s 244us/step - loss: 0.3596 - acc: 0.8386 - val_loss: 0.4492 - val_acc: 0.8171\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s 257us/step - loss: 0.3917 - acc: 0.8257 - val_loss: 0.4480 - val_acc: 0.8171\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s 245us/step - loss: 0.3693 - acc: 0.8214 - val_loss: 0.4514 - val_acc: 0.8114\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s 260us/step - loss: 0.3832 - acc: 0.8257 - val_loss: 0.4516 - val_acc: 0.8171\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s 309us/step - loss: 0.3934 - acc: 0.8300 - val_loss: 0.4544 - val_acc: 0.8114\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s 291us/step - loss: 0.3938 - acc: 0.8386 - val_loss: 0.4579 - val_acc: 0.8114\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s 290us/step - loss: 0.3551 - acc: 0.8243 - val_loss: 0.4592 - val_acc: 0.8171\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.3516 - acc: 0.8229 - val_loss: 0.5224 - val_acc: 0.8171\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s 241us/step - loss: 0.3575 - acc: 0.8300 - val_loss: 0.4647 - val_acc: 0.8171\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s 254us/step - loss: 0.3518 - acc: 0.8400 - val_loss: 0.4724 - val_acc: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.3507 - acc: 0.8414 - val_loss: 0.4682 - val_acc: 0.7943\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s 260us/step - loss: 0.3508 - acc: 0.8357 - val_loss: 0.5333 - val_acc: 0.7943\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.3501 - acc: 0.8329 - val_loss: 0.5137 - val_acc: 0.8114\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s 245us/step - loss: 0.3690 - acc: 0.8414 - val_loss: 0.4787 - val_acc: 0.7943\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.3503 - acc: 0.8343 - val_loss: 0.5356 - val_acc: 0.7943\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s 239us/step - loss: 0.3367 - acc: 0.8457 - val_loss: 0.5282 - val_acc: 0.8171\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.3496 - acc: 0.8386 - val_loss: 0.5270 - val_acc: 0.8171\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s 238us/step - loss: 0.3413 - acc: 0.8386 - val_loss: 0.5288 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s 269us/step - loss: 0.3630 - acc: 0.8386 - val_loss: 0.5431 - val_acc: 0.7829\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s 300us/step - loss: 0.4022 - acc: 0.8300 - val_loss: 0.5403 - val_acc: 0.7943\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s 262us/step - loss: 0.3413 - acc: 0.8400 - val_loss: 0.5525 - val_acc: 0.7829\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s 283us/step - loss: 0.3413 - acc: 0.8371 - val_loss: 0.5281 - val_acc: 0.7886\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.3404 - acc: 0.8400 - val_loss: 0.5498 - val_acc: 0.7886\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s 294us/step - loss: 0.3592 - acc: 0.8414 - val_loss: 0.5193 - val_acc: 0.7943\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s 274us/step - loss: 0.3356 - acc: 0.8400 - val_loss: 0.5261 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s 246us/step - loss: 0.3403 - acc: 0.8343 - val_loss: 0.5372 - val_acc: 0.7943\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s 224us/step - loss: 0.3378 - acc: 0.8443 - val_loss: 0.5274 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s 249us/step - loss: 0.3345 - acc: 0.8443 - val_loss: 0.5278 - val_acc: 0.7943\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s 245us/step - loss: 0.3300 - acc: 0.8371 - val_loss: 0.5265 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s 258us/step - loss: 0.3306 - acc: 0.8371 - val_loss: 0.5386 - val_acc: 0.7886\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s 277us/step - loss: 0.3340 - acc: 0.8429 - val_loss: 0.5301 - val_acc: 0.8057\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s 274us/step - loss: 0.3349 - acc: 0.8329 - val_loss: 0.5408 - val_acc: 0.7943\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s 290us/step - loss: 0.3318 - acc: 0.8429 - val_loss: 0.5369 - val_acc: 0.8057\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s 246us/step - loss: 0.3448 - acc: 0.8371 - val_loss: 0.5401 - val_acc: 0.8057\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s 268us/step - loss: 0.3219 - acc: 0.8429 - val_loss: 0.5386 - val_acc: 0.8229\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s 284us/step - loss: 0.3194 - acc: 0.8486 - val_loss: 0.5360 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s 258us/step - loss: 0.3485 - acc: 0.8343 - val_loss: 0.5422 - val_acc: 0.7943\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s 237us/step - loss: 0.3444 - acc: 0.8343 - val_loss: 0.5313 - val_acc: 0.8171\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s 243us/step - loss: 0.3434 - acc: 0.8600 - val_loss: 0.5437 - val_acc: 0.7886\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s 266us/step - loss: 0.3245 - acc: 0.8386 - val_loss: 0.5418 - val_acc: 0.7886\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s 271us/step - loss: 0.3207 - acc: 0.8471 - val_loss: 0.5385 - val_acc: 0.7829\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s 202us/step - loss: 0.3140 - acc: 0.8500 - val_loss: 0.5582 - val_acc: 0.7886\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.3252 - acc: 0.8443 - val_loss: 0.5377 - val_acc: 0.7943\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.3219 - acc: 0.8371 - val_loss: 0.5603 - val_acc: 0.7886\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.3101 - acc: 0.8471 - val_loss: 0.5278 - val_acc: 0.7886\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.3149 - acc: 0.8386 - val_loss: 0.5564 - val_acc: 0.7829\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.3103 - acc: 0.8443 - val_loss: 0.5494 - val_acc: 0.7829\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.3165 - acc: 0.8443 - val_loss: 0.5417 - val_acc: 0.7829\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.3375 - acc: 0.8386 - val_loss: 0.5573 - val_acc: 0.7829\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.3177 - acc: 0.8329 - val_loss: 0.5386 - val_acc: 0.7886\n"
     ]
    }
   ],
   "source": [
    "noOfEpochs = 100\n",
    "\n",
    "lead_2_input_data  = layers.Input(shape=(lead_2_scan_length, 15))\n",
    "raw_ecg_input_data = layers.Input(shape=(raw_ecg_scan_length, 12))\n",
    "\n",
    "lead_2_model = lead2Model(lead_2_input_data)\n",
    "\n",
    "lead_2_model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "history=lead_2_model.fit(X_LeadII_train, Y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.6836 - acc: 0.5771\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 0s 176us/step - loss: 0.6471 - acc: 0.7669\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 0s 170us/step - loss: 0.6110 - acc: 0.7794\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 0s 173us/step - loss: 0.5692 - acc: 0.7806\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 0s 158us/step - loss: 0.5319 - acc: 0.7909\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 0s 160us/step - loss: 0.4965 - acc: 0.7989\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 0s 172us/step - loss: 0.4728 - acc: 0.8034\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 0s 206us/step - loss: 0.4630 - acc: 0.7966\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 0s 226us/step - loss: 0.4568 - acc: 0.8057\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 0s 203us/step - loss: 0.4480 - acc: 0.8091\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 0s 208us/step - loss: 0.4425 - acc: 0.8091\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 0s 176us/step - loss: 0.4456 - acc: 0.8080\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 0s 192us/step - loss: 0.4385 - acc: 0.8160\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 0s 213us/step - loss: 0.4391 - acc: 0.8149\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 0s 169us/step - loss: 0.4374 - acc: 0.8057\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 0s 180us/step - loss: 0.4363 - acc: 0.8171\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 0s 174us/step - loss: 0.4384 - acc: 0.8034\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 0s 164us/step - loss: 0.4344 - acc: 0.8206\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 0s 183us/step - loss: 0.4288 - acc: 0.8069\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 0s 181us/step - loss: 0.4327 - acc: 0.8194\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 0s 219us/step - loss: 0.4278 - acc: 0.8194\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 0s 241us/step - loss: 0.4315 - acc: 0.8171\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 0s 173us/step - loss: 0.4288 - acc: 0.8183\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 0s 168us/step - loss: 0.4298 - acc: 0.8023\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 0s 200us/step - loss: 0.4346 - acc: 0.8263\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 0s 177us/step - loss: 0.4238 - acc: 0.8206\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 0s 198us/step - loss: 0.4282 - acc: 0.8206\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 0s 145us/step - loss: 0.4236 - acc: 0.8217\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 0s 153us/step - loss: 0.4270 - acc: 0.8137\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 0s 245us/step - loss: 0.4276 - acc: 0.8149\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 0s 235us/step - loss: 0.4209 - acc: 0.8217\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 0s 229us/step - loss: 0.4251 - acc: 0.8160\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 0s 224us/step - loss: 0.4177 - acc: 0.8183\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 0s 235us/step - loss: 0.4217 - acc: 0.8229\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 0s 234us/step - loss: 0.4159 - acc: 0.8240\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 0s 218us/step - loss: 0.4214 - acc: 0.8183\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 0s 207us/step - loss: 0.4169 - acc: 0.8217\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 0s 184us/step - loss: 0.4202 - acc: 0.8240\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 0s 158us/step - loss: 0.4173 - acc: 0.8217\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 0s 146us/step - loss: 0.4121 - acc: 0.8251\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 0s 173us/step - loss: 0.4156 - acc: 0.8240\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 0s 157us/step - loss: 0.4162 - acc: 0.8240\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 0s 145us/step - loss: 0.4070 - acc: 0.8229\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 0s 155us/step - loss: 0.4108 - acc: 0.8286\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 0s 139us/step - loss: 0.4065 - acc: 0.8229\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 0s 179us/step - loss: 0.4026 - acc: 0.8240\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 0s 281us/step - loss: 0.4050 - acc: 0.8240\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 0s 253us/step - loss: 0.4058 - acc: 0.8229\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 0s 221us/step - loss: 0.4014 - acc: 0.8251\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 0s 267us/step - loss: 0.4016 - acc: 0.8389\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 0s 261us/step - loss: 0.3987 - acc: 0.8354\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 0s 241us/step - loss: 0.4080 - acc: 0.8217\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 0s 297us/step - loss: 0.4020 - acc: 0.8331\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 0s 298us/step - loss: 0.3966 - acc: 0.8377\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 0s 334us/step - loss: 0.3980 - acc: 0.8354\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 0s 265us/step - loss: 0.3976 - acc: 0.8389\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 0s 279us/step - loss: 0.3989 - acc: 0.8309\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 0s 291us/step - loss: 0.4005 - acc: 0.8354\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 0s 270us/step - loss: 0.3953 - acc: 0.8309\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 0s 224us/step - loss: 0.3949 - acc: 0.8320\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 0s 245us/step - loss: 0.3937 - acc: 0.8331\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 0s 198us/step - loss: 0.3907 - acc: 0.8377\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 0s 242us/step - loss: 0.3919 - acc: 0.8286\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 0s 236us/step - loss: 0.3893 - acc: 0.8423\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 0s 217us/step - loss: 0.3922 - acc: 0.8309\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 0s 284us/step - loss: 0.3942 - acc: 0.8320\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 0s 236us/step - loss: 0.3894 - acc: 0.8354\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 0s 240us/step - loss: 0.3894 - acc: 0.8377\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 0s 179us/step - loss: 0.3833 - acc: 0.8377\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 0s 167us/step - loss: 0.3903 - acc: 0.8354\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 0s 197us/step - loss: 0.3819 - acc: 0.8366\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 0s 184us/step - loss: 0.3828 - acc: 0.8446\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 0s 205us/step - loss: 0.3885 - acc: 0.8400\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 0s 226us/step - loss: 0.3839 - acc: 0.8400\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 0s 258us/step - loss: 0.3847 - acc: 0.8434\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 0s 287us/step - loss: 0.3754 - acc: 0.8434\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 0s 288us/step - loss: 0.3800 - acc: 0.8400\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 0s 283us/step - loss: 0.3838 - acc: 0.8389\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 0s 283us/step - loss: 0.3859 - acc: 0.8320\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 0s 282us/step - loss: 0.3831 - acc: 0.8354\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 0s 250us/step - loss: 0.3790 - acc: 0.8457\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 0s 206us/step - loss: 0.3785 - acc: 0.8457\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 0s 174us/step - loss: 0.3719 - acc: 0.8423\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 0s 159us/step - loss: 0.3788 - acc: 0.8423\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 0s 159us/step - loss: 0.3791 - acc: 0.8389\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 0s 155us/step - loss: 0.3745 - acc: 0.8446\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 0s 176us/step - loss: 0.3799 - acc: 0.8423\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 0s 172us/step - loss: 0.3749 - acc: 0.8514\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 0s 173us/step - loss: 0.3738 - acc: 0.8503\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 0s 157us/step - loss: 0.3696 - acc: 0.8411\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 0s 212us/step - loss: 0.3706 - acc: 0.8469\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 0s 215us/step - loss: 0.3697 - acc: 0.8446\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 0s 165us/step - loss: 0.3666 - acc: 0.8503\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 0s 165us/step - loss: 0.3614 - acc: 0.8491\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 0s 200us/step - loss: 0.3716 - acc: 0.8514\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 0s 179us/step - loss: 0.3640 - acc: 0.8503\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 0s 211us/step - loss: 0.3669 - acc: 0.8480\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 0s 228us/step - loss: 0.3620 - acc: 0.8571\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 0s 185us/step - loss: 0.3633 - acc: 0.8560\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 0s 180us/step - loss: 0.3605 - acc: 0.8549\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 15s 17ms/step - loss: 0.8196 - acc: 0.5863\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5729 - acc: 0.7086\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5431 - acc: 0.7394\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4558 - acc: 0.7874\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3959 - acc: 0.8183\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3823 - acc: 0.8366\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3375 - acc: 0.8594\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3099 - acc: 0.8640\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3203 - acc: 0.8629\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2829 - acc: 0.8697\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2709 - acc: 0.8686\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2694 - acc: 0.8857\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2608 - acc: 0.8914\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2467 - acc: 0.8994\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2504 - acc: 0.8949\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2433 - acc: 0.8949\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2474 - acc: 0.8926\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2241 - acc: 0.9040\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2284 - acc: 0.9051\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2410 - acc: 0.8983\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2137 - acc: 0.9109\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2205 - acc: 0.9040\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2105 - acc: 0.9097\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2032 - acc: 0.9051\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1916 - acc: 0.9120\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1873 - acc: 0.9223\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1714 - acc: 0.9280\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2080 - acc: 0.9143\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1949 - acc: 0.9154\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1602 - acc: 0.9314\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2015 - acc: 0.9234\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1747 - acc: 0.9257\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1660 - acc: 0.9417\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1811 - acc: 0.9269\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1568 - acc: 0.9383\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1457 - acc: 0.9371\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1715 - acc: 0.9280\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1582 - acc: 0.9291\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1572 - acc: 0.9406\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1564 - acc: 0.9383\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1826 - acc: 0.9177\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1510 - acc: 0.9440\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1444 - acc: 0.9394\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1457 - acc: 0.9406\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1477 - acc: 0.9360\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1535 - acc: 0.9337\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1430 - acc: 0.9429\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1492 - acc: 0.9234\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1334 - acc: 0.9554\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1353 - acc: 0.9417\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1358 - acc: 0.9383\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1266 - acc: 0.9486\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1217 - acc: 0.9531\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1339 - acc: 0.9371\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1386 - acc: 0.9417\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1291 - acc: 0.9406\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1305 - acc: 0.9520\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1299 - acc: 0.9474\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1174 - acc: 0.9509\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1252 - acc: 0.9429\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1254 - acc: 0.9486\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1088 - acc: 0.9566\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1326 - acc: 0.9451\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1009 - acc: 0.9566\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1155 - acc: 0.9566\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1092 - acc: 0.9646\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1001 - acc: 0.9577\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0995 - acc: 0.9623\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1175 - acc: 0.9509\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1278 - acc: 0.9531\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1055 - acc: 0.9600\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1116 - acc: 0.9554\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1320 - acc: 0.9406\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1062 - acc: 0.9577\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1165 - acc: 0.9543\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1078 - acc: 0.9589\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1067 - acc: 0.9680\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0940 - acc: 0.9657\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0850 - acc: 0.9669\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0902 - acc: 0.9611\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1133 - acc: 0.9543\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1125 - acc: 0.9577\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1059 - acc: 0.9566\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0860 - acc: 0.9669\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1023 - acc: 0.9566\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1058 - acc: 0.9611\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0940 - acc: 0.9657\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1082 - acc: 0.9600\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0892 - acc: 0.9600\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0943 - acc: 0.9623\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0878 - acc: 0.9634\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1027 - acc: 0.9589\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1046 - acc: 0.9577\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1023 - acc: 0.9611\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0913 - acc: 0.9623\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0890 - acc: 0.9691\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0781 - acc: 0.9726\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.0984 - acc: 0.9566\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1227 - acc: 0.9543\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.1038 - acc: 0.9589\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.8517 - acc: 0.5931\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6671 - acc: 0.6743\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6584 - acc: 0.6834\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6140 - acc: 0.7154\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5400 - acc: 0.7474\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5707 - acc: 0.7349\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5292 - acc: 0.7680\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5595 - acc: 0.7589\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5214 - acc: 0.7657\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5058 - acc: 0.7680\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4855 - acc: 0.7806\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4658 - acc: 0.8000\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4887 - acc: 0.7714\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4597 - acc: 0.7760\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4681 - acc: 0.7840\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4463 - acc: 0.7840\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4415 - acc: 0.8091\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4380 - acc: 0.8149\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4079 - acc: 0.8251\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4387 - acc: 0.8057\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4031 - acc: 0.8229\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4277 - acc: 0.8103\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4088 - acc: 0.8229\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3841 - acc: 0.8309\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4111 - acc: 0.8103\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4100 - acc: 0.8126\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3772 - acc: 0.8343\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3777 - acc: 0.8320\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3731 - acc: 0.8343\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3547 - acc: 0.8423\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3399 - acc: 0.8480\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3617 - acc: 0.8354\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3550 - acc: 0.8286\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3407 - acc: 0.8297\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3314 - acc: 0.8503\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3275 - acc: 0.8491\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3631 - acc: 0.8411\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3463 - acc: 0.8331\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3264 - acc: 0.8526\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3336 - acc: 0.8560\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3345 - acc: 0.8514\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3313 - acc: 0.8434\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3152 - acc: 0.8537\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3481 - acc: 0.8469\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3039 - acc: 0.8606\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3174 - acc: 0.8629\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3396 - acc: 0.8423\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3245 - acc: 0.8469\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3046 - acc: 0.8617\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3264 - acc: 0.8526\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2935 - acc: 0.8629\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3025 - acc: 0.8549\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3058 - acc: 0.8549\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3004 - acc: 0.8594\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2846 - acc: 0.8709\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3026 - acc: 0.8480\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3122 - acc: 0.8549\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2807 - acc: 0.8720\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2747 - acc: 0.8640\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2770 - acc: 0.8743\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2839 - acc: 0.8811\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2804 - acc: 0.8617\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2772 - acc: 0.8720\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3106 - acc: 0.8571\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2857 - acc: 0.8720\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2731 - acc: 0.8731\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2947 - acc: 0.8709\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2961 - acc: 0.8594\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2558 - acc: 0.8823\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2743 - acc: 0.8754\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2732 - acc: 0.8789\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2956 - acc: 0.8503\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2640 - acc: 0.8846\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2844 - acc: 0.8720\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2767 - acc: 0.8846\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2516 - acc: 0.8800\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2850 - acc: 0.8674\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2667 - acc: 0.8754\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2586 - acc: 0.8857\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2800 - acc: 0.8754\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2765 - acc: 0.8697\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2503 - acc: 0.8914\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2709 - acc: 0.8674\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2477 - acc: 0.8857\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2736 - acc: 0.8834\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2665 - acc: 0.8743\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2451 - acc: 0.8971\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2729 - acc: 0.8789\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2483 - acc: 0.8834\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2684 - acc: 0.8766\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2677 - acc: 0.8823\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2484 - acc: 0.8960\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2235 - acc: 0.8903\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2428 - acc: 0.8846\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2453 - acc: 0.8834\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2518 - acc: 0.8937\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2066 - acc: 0.8960\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2216 - acc: 0.9063\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2487 - acc: 0.8937\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2253 - acc: 0.8903\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 10s 11ms/step - loss: 0.7648 - acc: 0.5600\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.6370 - acc: 0.6697\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.6441 - acc: 0.7017\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.6361 - acc: 0.6640\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.6030 - acc: 0.6983\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5961 - acc: 0.7006\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5854 - acc: 0.7177\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5773 - acc: 0.6971\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5431 - acc: 0.7440\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5634 - acc: 0.7371\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5561 - acc: 0.7120\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5324 - acc: 0.7291\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5513 - acc: 0.7314\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5227 - acc: 0.7634\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5231 - acc: 0.7577\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5114 - acc: 0.7520\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5474 - acc: 0.7497\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5278 - acc: 0.7543\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4939 - acc: 0.7634\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5348 - acc: 0.7486\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4857 - acc: 0.7634\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5022 - acc: 0.7589\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4939 - acc: 0.7737\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4964 - acc: 0.7783\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4976 - acc: 0.7611\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4681 - acc: 0.7691\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4925 - acc: 0.7600\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4771 - acc: 0.7829\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4801 - acc: 0.7749\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4924 - acc: 0.7554\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4790 - acc: 0.7794\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4719 - acc: 0.7646\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4670 - acc: 0.7749\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4519 - acc: 0.7806\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4733 - acc: 0.7920\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4631 - acc: 0.7909\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4611 - acc: 0.7703\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4776 - acc: 0.7657\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4266 - acc: 0.7989\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4552 - acc: 0.7874\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4377 - acc: 0.7851\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4337 - acc: 0.7897\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4478 - acc: 0.7909\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4146 - acc: 0.8160\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3987 - acc: 0.8217\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4248 - acc: 0.7931\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4212 - acc: 0.7931\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4055 - acc: 0.8023\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3980 - acc: 0.8171\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4117 - acc: 0.8137\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3857 - acc: 0.8263\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4243 - acc: 0.8080\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4124 - acc: 0.8126\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3841 - acc: 0.8251\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4009 - acc: 0.8217\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4112 - acc: 0.8114\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4209 - acc: 0.7977\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3989 - acc: 0.8046\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3798 - acc: 0.8309\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4087 - acc: 0.8091\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4064 - acc: 0.8103\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3969 - acc: 0.8149\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4046 - acc: 0.8046\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3888 - acc: 0.8309\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3830 - acc: 0.8114\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3653 - acc: 0.8320\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3903 - acc: 0.8149\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3813 - acc: 0.8171\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3771 - acc: 0.8286\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3690 - acc: 0.8137\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3691 - acc: 0.8126\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3456 - acc: 0.8457\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3816 - acc: 0.8366\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3827 - acc: 0.8263\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3738 - acc: 0.8309\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3664 - acc: 0.8286\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3432 - acc: 0.8331\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3625 - acc: 0.8240\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3600 - acc: 0.8343\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3429 - acc: 0.8457\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3566 - acc: 0.8434\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3621 - acc: 0.8297\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3513 - acc: 0.8354\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3460 - acc: 0.8480\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3302 - acc: 0.8469\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3476 - acc: 0.8354\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3281 - acc: 0.8526\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3515 - acc: 0.8309\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3319 - acc: 0.8503\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3367 - acc: 0.8400\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3299 - acc: 0.8434\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3197 - acc: 0.8606\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3280 - acc: 0.8549\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3530 - acc: 0.8263\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3114 - acc: 0.8491\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3235 - acc: 0.8503\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3279 - acc: 0.8571\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3595 - acc: 0.8389\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3143 - acc: 0.8560\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3204 - acc: 0.8469\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 15s 17ms/step - loss: 0.7321 - acc: 0.6491\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.6397 - acc: 0.6811\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.6125 - acc: 0.7063\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5533 - acc: 0.7383\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5595 - acc: 0.7417\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5187 - acc: 0.7577\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4993 - acc: 0.7657\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4923 - acc: 0.7771\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4864 - acc: 0.7760\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4756 - acc: 0.7760\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4395 - acc: 0.7966\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4439 - acc: 0.8034\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4716 - acc: 0.7954\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4483 - acc: 0.7897\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4366 - acc: 0.8034\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4296 - acc: 0.8149\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4046 - acc: 0.8069\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4100 - acc: 0.8011\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3999 - acc: 0.8229\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3974 - acc: 0.8217\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4086 - acc: 0.8034\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4009 - acc: 0.8274\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3698 - acc: 0.8206\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3624 - acc: 0.8400\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3562 - acc: 0.8377\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3670 - acc: 0.8274\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3644 - acc: 0.8446\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3576 - acc: 0.8331\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3411 - acc: 0.8480\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3475 - acc: 0.8446\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3575 - acc: 0.8469\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3099 - acc: 0.8549\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3355 - acc: 0.8491\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3005 - acc: 0.8651\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3528 - acc: 0.8206\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3416 - acc: 0.8343\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3153 - acc: 0.8663\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3061 - acc: 0.8560\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3212 - acc: 0.8446\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3372 - acc: 0.8446\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3254 - acc: 0.8606\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2893 - acc: 0.8640\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3199 - acc: 0.8560\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3056 - acc: 0.8731\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2833 - acc: 0.8766\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2987 - acc: 0.8674\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2835 - acc: 0.8800\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2562 - acc: 0.8789\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3097 - acc: 0.8583\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2837 - acc: 0.8743\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2920 - acc: 0.8526\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2752 - acc: 0.8880\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2865 - acc: 0.8754\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2718 - acc: 0.8731\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2671 - acc: 0.8731\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2772 - acc: 0.8857\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2761 - acc: 0.8731\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2455 - acc: 0.8926\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2415 - acc: 0.8903\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2778 - acc: 0.8743\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2726 - acc: 0.8766\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2521 - acc: 0.8926\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2636 - acc: 0.8823\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2663 - acc: 0.8777\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2187 - acc: 0.9131\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2507 - acc: 0.8903\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2632 - acc: 0.8777\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2634 - acc: 0.8743\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2372 - acc: 0.8880\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2573 - acc: 0.8766\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2579 - acc: 0.8914\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2407 - acc: 0.8800\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2742 - acc: 0.8731\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2499 - acc: 0.8960\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2425 - acc: 0.8960\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2424 - acc: 0.8949\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2334 - acc: 0.8926\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2722 - acc: 0.8857\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2449 - acc: 0.8994\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2567 - acc: 0.8811\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2661 - acc: 0.8754\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2306 - acc: 0.8960\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2518 - acc: 0.8823\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2375 - acc: 0.8914\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2229 - acc: 0.9029\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2372 - acc: 0.8926\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2629 - acc: 0.8869\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2207 - acc: 0.8971\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2319 - acc: 0.8949\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2566 - acc: 0.8823\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2503 - acc: 0.8777\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2553 - acc: 0.8880\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2461 - acc: 0.8891\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2129 - acc: 0.8994\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2421 - acc: 0.8971\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2177 - acc: 0.9051\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2281 - acc: 0.8743\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2167 - acc: 0.9040\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2106 - acc: 0.9051\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2175 - acc: 0.8880\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 24s 27ms/step - loss: 0.9686 - acc: 0.4171\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.7554 - acc: 0.5520\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 13s 15ms/step - loss: 0.6608 - acc: 0.6171\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.6068 - acc: 0.6686\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.5961 - acc: 0.6869\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5809 - acc: 0.6903\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.5844 - acc: 0.6983\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5673 - acc: 0.7200\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.5305 - acc: 0.7246\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5468 - acc: 0.7394\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5458 - acc: 0.7280\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5167 - acc: 0.7623\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.5453 - acc: 0.7326\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.5114 - acc: 0.7577\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5140 - acc: 0.7554\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.5068 - acc: 0.7383\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4925 - acc: 0.7577\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.4745 - acc: 0.7749\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4738 - acc: 0.7840\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5238 - acc: 0.7383\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4729 - acc: 0.7794\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.4598 - acc: 0.7749\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4479 - acc: 0.7840\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4577 - acc: 0.7646\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.4575 - acc: 0.7874\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4295 - acc: 0.7943\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.4331 - acc: 0.7931\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4577 - acc: 0.7726\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4278 - acc: 0.7977\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4296 - acc: 0.8046\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4328 - acc: 0.7874\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4087 - acc: 0.8000\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4029 - acc: 0.8251\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4299 - acc: 0.8011\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4055 - acc: 0.7920\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.4159 - acc: 0.8034\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3991 - acc: 0.8080\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3864 - acc: 0.8194\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3988 - acc: 0.8217\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.4148 - acc: 0.8057\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4105 - acc: 0.8023\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3876 - acc: 0.8217\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3807 - acc: 0.8183\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4087 - acc: 0.8080\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.4188 - acc: 0.7977\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4035 - acc: 0.8046\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3812 - acc: 0.8343\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3755 - acc: 0.8377\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3713 - acc: 0.8194\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3725 - acc: 0.8240\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3712 - acc: 0.8274\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3504 - acc: 0.8377\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3608 - acc: 0.8389\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3639 - acc: 0.8331\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3836 - acc: 0.8286\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3704 - acc: 0.8229\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3868 - acc: 0.8126\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3730 - acc: 0.8263\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3883 - acc: 0.8091\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3667 - acc: 0.8354\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3592 - acc: 0.8297\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3428 - acc: 0.8457\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3320 - acc: 0.8457\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3641 - acc: 0.8389\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3406 - acc: 0.8480\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3549 - acc: 0.8446\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3247 - acc: 0.8446\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3529 - acc: 0.8423\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3219 - acc: 0.8423\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3263 - acc: 0.8411\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3225 - acc: 0.8526\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3376 - acc: 0.8503\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3414 - acc: 0.8411\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3474 - acc: 0.8354\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3355 - acc: 0.8514\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3434 - acc: 0.8480\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3043 - acc: 0.8549\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3232 - acc: 0.8423\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3011 - acc: 0.8503\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3049 - acc: 0.8800\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.2927 - acc: 0.8617\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3016 - acc: 0.8571\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3143 - acc: 0.8549\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3039 - acc: 0.8583\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3119 - acc: 0.8617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3293 - acc: 0.8503\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3014 - acc: 0.8651\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3184 - acc: 0.8411\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.2997 - acc: 0.8606\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.2943 - acc: 0.8674\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.3016 - acc: 0.8629\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.2901 - acc: 0.8731\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3063 - acc: 0.8606\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3144 - acc: 0.8594\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.3167 - acc: 0.8640\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3014 - acc: 0.8594\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.2945 - acc: 0.8594\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3061 - acc: 0.8549\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 14s 16ms/step - loss: 0.2729 - acc: 0.8789\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 14s 15ms/step - loss: 0.2939 - acc: 0.8583\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 23s 26ms/step - loss: 0.8398 - acc: 0.4411\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.7196 - acc: 0.5634\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.6397 - acc: 0.6571\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.6233 - acc: 0.6537\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.6172 - acc: 0.6697\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5671 - acc: 0.6983\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.6158 - acc: 0.6754\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.6075 - acc: 0.6640\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5801 - acc: 0.6857\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5901 - acc: 0.6926\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5872 - acc: 0.6994\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5743 - acc: 0.7189\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5756 - acc: 0.6983\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5785 - acc: 0.6949\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.6030 - acc: 0.6834\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5716 - acc: 0.7063\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5274 - acc: 0.7177\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5474 - acc: 0.7406\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5385 - acc: 0.7280\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5449 - acc: 0.7177\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.5415 - acc: 0.7371\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5501 - acc: 0.7314\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5411 - acc: 0.7337\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5611 - acc: 0.7143\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5334 - acc: 0.7417\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5506 - acc: 0.7051\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5448 - acc: 0.7189\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.5500 - acc: 0.7211\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5377 - acc: 0.7371\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.5208 - acc: 0.7337\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5244 - acc: 0.7371\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4982 - acc: 0.7611\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4971 - acc: 0.7749\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.5402 - acc: 0.7246\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5261 - acc: 0.7211\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5202 - acc: 0.7554\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5301 - acc: 0.7223\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5157 - acc: 0.7440\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5192 - acc: 0.7451\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.5172 - acc: 0.7280\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5065 - acc: 0.7566\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5267 - acc: 0.7451\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 11s 13ms/step - loss: 0.4992 - acc: 0.7531\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.5042 - acc: 0.7349\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4976 - acc: 0.7543\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5048 - acc: 0.7463\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4802 - acc: 0.7760\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4969 - acc: 0.7463\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4961 - acc: 0.7680\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.5030 - acc: 0.7737\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4837 - acc: 0.7726\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4794 - acc: 0.7646\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4723 - acc: 0.7680\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4988 - acc: 0.7417\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5073 - acc: 0.7600\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.5054 - acc: 0.7577\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4982 - acc: 0.7623\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4615 - acc: 0.7703\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4938 - acc: 0.7589\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4632 - acc: 0.7669\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4643 - acc: 0.7829\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4895 - acc: 0.7680\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4615 - acc: 0.7703\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4732 - acc: 0.7714\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4819 - acc: 0.7726\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4793 - acc: 0.7589\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4929 - acc: 0.7749\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4594 - acc: 0.7691\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4732 - acc: 0.7646\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4601 - acc: 0.7943\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4771 - acc: 0.7714\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4813 - acc: 0.7794\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4497 - acc: 0.7874\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4555 - acc: 0.7817\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4663 - acc: 0.7760\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4757 - acc: 0.7680\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4632 - acc: 0.7737\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4733 - acc: 0.7749\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4706 - acc: 0.7646\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4557 - acc: 0.7806\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4414 - acc: 0.7874\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4564 - acc: 0.7886\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4622 - acc: 0.7771\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4520 - acc: 0.7966\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4684 - acc: 0.7886\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4451 - acc: 0.7829\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4364 - acc: 0.7954\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4330 - acc: 0.8000\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4379 - acc: 0.7806\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4444 - acc: 0.7977\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4574 - acc: 0.7851\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4517 - acc: 0.7863\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4496 - acc: 0.7851\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4411 - acc: 0.7806\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4536 - acc: 0.7806\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4558 - acc: 0.7806\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4292 - acc: 0.7851\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 12s 13ms/step - loss: 0.4134 - acc: 0.8183\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4102 - acc: 0.8114\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 12s 14ms/step - loss: 0.4323 - acc: 0.7920\n"
     ]
    }
   ],
   "source": [
    "noOfEpochs = 1\n",
    "\n",
    "validation_split_percent = 0.95\n",
    "\n",
    "lead_2_input_data  = layers.Input(shape=(lead_2_scan_length, 15))\n",
    "raw_ecg_input_data = layers.Input(shape=(raw_ecg_scan_length, 12))\n",
    "\n",
    "lead_2_model = lead2Model(lead_2_input_data)\n",
    "lead_2_model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "lead_2_model_history=lead_2_model.fit(X_LeadII_train, Y_train, epochs=noOfEpochs, batch_size=32, validation_split=validation_split_percent)\n",
    "\n",
    "\n",
    "rawecg_lead2_convseparableModel = rawecg_lead2_convseparable(lead_2_input_data, raw_ecg_input_data)\n",
    "rawecg_lead2_convseparableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "rawecg_lead2_convseparableModel_history=rawecg_lead2_convseparableModel.fit([X_LeadII_train, X_RawECG_train], Y_train, epochs=noOfEpochs, batch_size=32, validation_split=validation_split_percent)\n",
    "\n",
    "\n",
    "convolutioModel = baseModel_Conv1D(raw_ecg_input_data)\n",
    "convolutioModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "conv_history=convolutioModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, validation_split=validation_split_percent)\n",
    "\n",
    "separableModel = baseModel_Separable1D(raw_ecg_input_data)\n",
    "separableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "separableconv_history = separableModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, validation_split=validation_split_percent)\n",
    "    \n",
    "convSeparableModel = convSeparable(raw_ecg_input_data)\n",
    "convSeparableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "separableconv_history = convSeparableModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, validation_split=validation_split_percent)\n",
    "    \n",
    "    \n",
    "ConvGRUWithStridesModel = baseModel_ConvGRUWithStrides(raw_ecg_input_data)\n",
    "ConvGRUWithStridesModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "ConvGRUWithStridesModel_history = ConvGRUWithStridesModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, validation_split=validation_split_percent)\n",
    "   \n",
    "SeparableConvGRUWithStridesModel = baseModel_SeparableConvGRUWithStrides(raw_ecg_input_data)\n",
    "SeparableConvGRUWithStridesModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "SeparableConvGRUWithStridesModel_history = SeparableConvGRUWithStridesModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, validation_split=validation_split_percent)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembleWithAverage( model_input, models ):\n",
    "    outputs = [model.outputs[0] for model in models ]\n",
    "    output  = layers.Average()(outputs)\n",
    "    model = Model( model_input, output)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy for lead_2_model: 83.1050229127\n",
      "validation accuracy for rawecg_lead2_convseparableModel: 86.7579909492\n",
      "validation accuracy for convolutioModel: 84.4748861986\n",
      "validation accuracy for separableModel: 82.1917807131\n",
      "validation accuracy for convSeparableModel: 83.5616441894\n",
      "validation accuracy for ConvGRUWithStridesModel: 83.1050227222\n",
      "validation accuracy for SeparableConvGRUWithStridesModel: 77.168949935\n",
      "valiation accuracy for ensemble: 89.04109589041096\n"
     ]
    }
   ],
   "source": [
    "listOfBaseModels = [\n",
    "    lead_2_model,\n",
    "    convolutioModel,\n",
    "    separableModel,\n",
    "    convSeparableModel,\n",
    "    ConvGRUWithStridesModel,\n",
    "    SeparableConvGRUWithStridesModel,\n",
    "    rawecg_lead2_convseparableModel\n",
    "]\n",
    "\n",
    "ensemle_model = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "print('validation accuracy for lead_2_model: {}'.format( round( 100*lead_2_model.evaluate(X_LeadII_test, Y_test, verbose=2)[1], 10) ) )\n",
    "print('validation accuracy for rawecg_lead2_convseparableModel: {}'.format( round( 100*rawecg_lead2_convseparableModel.evaluate([X_LeadII_test, X_RawECG_test], Y_test, verbose=2)[1], 10) ) )\n",
    "print('validation accuracy for convolutioModel: {}'.format( round( 100*convolutioModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) ) )\n",
    "print('validation accuracy for separableModel: {}'.format( round( 100*separableModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) ) )\n",
    "print('validation accuracy for convSeparableModel: {}'.format( round( 100*convSeparableModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) ) )\n",
    "print('validation accuracy for ConvGRUWithStridesModel: {}'.format( round( 100*ConvGRUWithStridesModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) ) )\n",
    "print('validation accuracy for SeparableConvGRUWithStridesModel: {}'.format( round( 100*SeparableConvGRUWithStridesModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) ) )\n",
    "print('valiation accuracy for ensemble: {}'.format( \n",
    "                100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test ) \n",
    "                / \n",
    "                Y_test.shape[0]\n",
    "            )\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valiation accuracy for ensemble: 90.41095890410959\n",
      "valiation accuracy for ensemble: 89.95433789954338\n",
      "valiation accuracy for ensemble: 91.32420091324201\n"
     ]
    }
   ],
   "source": [
    "listOfBaseModels = [\n",
    "    lead_2_model,\n",
    "    convolutioModel,\n",
    "    separableModel,\n",
    "    convSeparableModel,\n",
    "    ConvGRUWithStridesModel,\n",
    "    rawecg_lead2_convseparableModel\n",
    "]\n",
    "ensemle_model = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "print('valiation accuracy for ensemble: {}'.format( \n",
    "                100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test ) \n",
    "                / \n",
    "                Y_test.shape[0]\n",
    "            )\n",
    "     )\n",
    "\n",
    "listOfBaseModels = [\n",
    "    lead_2_model,\n",
    "#     convolutioModel,\n",
    "#     separableModel,\n",
    "#     convSeparableModel,\n",
    "    ConvGRUWithStridesModel,\n",
    "    rawecg_lead2_convseparableModel\n",
    "]\n",
    "\n",
    "ensemle_model = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "print('valiation accuracy for ensemble: {}'.format( \n",
    "                100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test ) \n",
    "                / \n",
    "                Y_test.shape[0]\n",
    "            )\n",
    "     )\n",
    "\n",
    "listOfBaseModels = [\n",
    "    lead_2_model,\n",
    "    convSeparableModel,\n",
    "    ConvGRUWithStridesModel,\n",
    "    rawecg_lead2_convseparableModel\n",
    "]\n",
    "\n",
    "ensemle_model = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "print('valiation accuracy for ensemble: {}'.format( \n",
    "                100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test ) \n",
    "                / \n",
    "                Y_test.shape[0]\n",
    "            )\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RawECG       = np.array( RawEcgScan )\n",
    "X_LeadII       = np.array( LeadIIEcgScan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "250*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scanLength = [\n",
    "#     (5,10),\n",
    "#     (5,25),\n",
    "#     (5,50),\n",
    "#     (5,100),\n",
    "#     (10,10),\n",
    "#     (10,25),\n",
    "#     (10,50),\n",
    "#     (10,100),\n",
    "    (20,10),\n",
    "    (20,25),\n",
    "    (20,50),\n",
    "    (20,100),\n",
    "    (40,10),\n",
    "    (40,25),\n",
    "    (40,50),\n",
    "    (40,100),\n",
    "    (60,10),\n",
    "    (60,25),\n",
    "    (60,50),\n",
    "    (60,100),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "875/875 [==============================] - 1s 706us/step - loss: 0.6685 - acc: 0.7326\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 0s 128us/step - loss: 0.6295 - acc: 0.7566\n",
      "Epoch 3/100\n",
      "448/875 [==============>...............] - ETA: 0s - loss: 0.6008 - acc: 0.7634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:435: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 0s 124us/step - loss: 0.5881 - acc: 0.7714\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 0s 121us/step - loss: 0.5458 - acc: 0.7851\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 0s 129us/step - loss: 0.5056 - acc: 0.7977\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 0s 132us/step - loss: 0.4800 - acc: 0.8023\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 0s 212us/step - loss: 0.4623 - acc: 0.8057\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 0s 212us/step - loss: 0.4581 - acc: 0.8080\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 0s 227us/step - loss: 0.4488 - acc: 0.8149\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 0s 222us/step - loss: 0.4446 - acc: 0.8114\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 0s 232us/step - loss: 0.4418 - acc: 0.8126\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 0s 234us/step - loss: 0.4363 - acc: 0.8137\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 0s 221us/step - loss: 0.4307 - acc: 0.8183\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 0s 228us/step - loss: 0.4342 - acc: 0.8126\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 0s 224us/step - loss: 0.4339 - acc: 0.8137\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 0s 215us/step - loss: 0.4293 - acc: 0.8114\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 0s 242us/step - loss: 0.4305 - acc: 0.8183\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 0s 203us/step - loss: 0.4232 - acc: 0.8137\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 0s 204us/step - loss: 0.4302 - acc: 0.8114\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 0s 198us/step - loss: 0.4263 - acc: 0.8217\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 0s 233us/step - loss: 0.4311 - acc: 0.8171\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 0s 227us/step - loss: 0.4280 - acc: 0.8206\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 0s 238us/step - loss: 0.4192 - acc: 0.8114\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 0s 251us/step - loss: 0.4237 - acc: 0.8194\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 0s 237us/step - loss: 0.4197 - acc: 0.8160\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.4136 - acc: 0.829 - 0s 230us/step - loss: 0.4202 - acc: 0.8263\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 0s 237us/step - loss: 0.4169 - acc: 0.8229\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 0s 253us/step - loss: 0.4181 - acc: 0.8206\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 0s 220us/step - loss: 0.4232 - acc: 0.8194\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 0s 204us/step - loss: 0.4195 - acc: 0.8240\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 0s 219us/step - loss: 0.4201 - acc: 0.8171\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 0s 220us/step - loss: 0.4177 - acc: 0.8183\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 0s 221us/step - loss: 0.4182 - acc: 0.8206\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 0s 215us/step - loss: 0.4121 - acc: 0.8286\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 0s 200us/step - loss: 0.4058 - acc: 0.8263\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 0s 231us/step - loss: 0.4096 - acc: 0.8251\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 0s 223us/step - loss: 0.4066 - acc: 0.8263\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 0s 222us/step - loss: 0.4154 - acc: 0.8274\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 0s 229us/step - loss: 0.4135 - acc: 0.8194\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 0s 214us/step - loss: 0.4123 - acc: 0.8274\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 0s 240us/step - loss: 0.4085 - acc: 0.8274\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 0s 243us/step - loss: 0.4062 - acc: 0.8286\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 0s 231us/step - loss: 0.4044 - acc: 0.8297\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 0s 231us/step - loss: 0.4107 - acc: 0.8320\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 0s 241us/step - loss: 0.4066 - acc: 0.8309\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 0s 212us/step - loss: 0.3989 - acc: 0.8286\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 0s 224us/step - loss: 0.4049 - acc: 0.8343\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 0s 233us/step - loss: 0.4011 - acc: 0.8354\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 0s 222us/step - loss: 0.4048 - acc: 0.8274\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 0s 225us/step - loss: 0.4010 - acc: 0.8320\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 0s 219us/step - loss: 0.3973 - acc: 0.8343\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 0s 200us/step - loss: 0.3981 - acc: 0.8400\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 0s 189us/step - loss: 0.3976 - acc: 0.8343\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 0s 190us/step - loss: 0.3975 - acc: 0.8320\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 0s 185us/step - loss: 0.3993 - acc: 0.8331\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 0s 191us/step - loss: 0.3997 - acc: 0.8309\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 0s 193us/step - loss: 0.3951 - acc: 0.8354\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 0s 185us/step - loss: 0.3901 - acc: 0.8423\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 0s 180us/step - loss: 0.3976 - acc: 0.8389\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 0s 182us/step - loss: 0.3947 - acc: 0.8354\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 0s 210us/step - loss: 0.3974 - acc: 0.8297\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 0s 217us/step - loss: 0.3929 - acc: 0.8354\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 0s 209us/step - loss: 0.3908 - acc: 0.8411\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 0s 198us/step - loss: 0.3948 - acc: 0.8366\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 0s 193us/step - loss: 0.3896 - acc: 0.8423\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 0s 183us/step - loss: 0.3886 - acc: 0.8377\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 0s 166us/step - loss: 0.3900 - acc: 0.8434\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 0s 167us/step - loss: 0.3834 - acc: 0.8354\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 0s 199us/step - loss: 0.3870 - acc: 0.8480\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 0s 181us/step - loss: 0.3915 - acc: 0.8297\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 0s 202us/step - loss: 0.3787 - acc: 0.8446\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 0s 223us/step - loss: 0.3820 - acc: 0.8411\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 0s 228us/step - loss: 0.3784 - acc: 0.8366\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 0s 224us/step - loss: 0.3821 - acc: 0.8434 0s - loss: 0.4268 - acc: 0.8\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 0s 211us/step - loss: 0.3820 - acc: 0.8491 0s - loss: 0.3873 - acc: 0.8\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 0s 243us/step - loss: 0.3885 - acc: 0.8457\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 0s 240us/step - loss: 0.3890 - acc: 0.8457\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.3885 - acc: 0.839 - 0s 225us/step - loss: 0.3848 - acc: 0.8423\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 0s 233us/step - loss: 0.3808 - acc: 0.8423\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 0s 229us/step - loss: 0.3766 - acc: 0.8469\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 0s 219us/step - loss: 0.3763 - acc: 0.8469\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 0s 229us/step - loss: 0.3806 - acc: 0.8503\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 0s 231us/step - loss: 0.3776 - acc: 0.8480\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 0s 233us/step - loss: 0.3733 - acc: 0.8503\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 0s 227us/step - loss: 0.3748 - acc: 0.8549\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 0s 195us/step - loss: 0.3758 - acc: 0.8503\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 0s 183us/step - loss: 0.3782 - acc: 0.8469\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 0s 197us/step - loss: 0.3777 - acc: 0.8560\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 0s 192us/step - loss: 0.3684 - acc: 0.8560\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 0s 176us/step - loss: 0.3702 - acc: 0.8480\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 0s 158us/step - loss: 0.3704 - acc: 0.8480\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 0s 172us/step - loss: 0.3715 - acc: 0.8491\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 0s 170us/step - loss: 0.3713 - acc: 0.8514\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 0s 177us/step - loss: 0.3630 - acc: 0.8537\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.3741 - acc: 0.850 - 0s 225us/step - loss: 0.3675 - acc: 0.8514\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 0s 267us/step - loss: 0.3658 - acc: 0.8514\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 0s 240us/step - loss: 0.3643 - acc: 0.8560\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 0s 216us/step - loss: 0.3617 - acc: 0.8571\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 0s 243us/step - loss: 0.3650 - acc: 0.8514\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 0s 220us/step - loss: 0.3675 - acc: 0.8571\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 10s 11ms/step - loss: 0.6195 - acc: 0.6549\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5333 - acc: 0.7486\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4147 - acc: 0.8103\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3830 - acc: 0.8297\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3693 - acc: 0.8411\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3611 - acc: 0.8343\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3390 - acc: 0.8549\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3111 - acc: 0.8571\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3101 - acc: 0.8651\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2793 - acc: 0.8686\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2725 - acc: 0.8857\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2517 - acc: 0.8983\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2563 - acc: 0.8834\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2281 - acc: 0.9017\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2281 - acc: 0.9074\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2142 - acc: 0.9051\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2152 - acc: 0.9120\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2137 - acc: 0.9097\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1938 - acc: 0.9234\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1891 - acc: 0.9234\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2140 - acc: 0.9063\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1861 - acc: 0.9200\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1948 - acc: 0.9223\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1720 - acc: 0.9269\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1740 - acc: 0.9211\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1791 - acc: 0.9211\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1572 - acc: 0.9314\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1710 - acc: 0.9314\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1580 - acc: 0.9360\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1609 - acc: 0.9291\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1382 - acc: 0.9440\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1600 - acc: 0.9303\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1419 - acc: 0.9326\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1725 - acc: 0.9257\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1400 - acc: 0.9417\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1259 - acc: 0.9531\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1500 - acc: 0.9383\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1428 - acc: 0.9463\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1444 - acc: 0.9451\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1289 - acc: 0.9474\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1284 - acc: 0.9463\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1200 - acc: 0.9497\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1177 - acc: 0.9554\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1300 - acc: 0.9463\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1081 - acc: 0.9566\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1270 - acc: 0.9463\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1150 - acc: 0.9589\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1155 - acc: 0.9520\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0999 - acc: 0.9577\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1095 - acc: 0.9577\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1273 - acc: 0.9531\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1125 - acc: 0.9509\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1060 - acc: 0.9600\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1142 - acc: 0.9554\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1090 - acc: 0.9554\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1035 - acc: 0.9623\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0969 - acc: 0.9646\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1087 - acc: 0.9577\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1002 - acc: 0.9589\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0922 - acc: 0.9646\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0888 - acc: 0.9657\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0854 - acc: 0.9646\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0951 - acc: 0.9714\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0873 - acc: 0.9646\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1076 - acc: 0.9520\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0940 - acc: 0.9646\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0825 - acc: 0.9623\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0954 - acc: 0.9623\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0800 - acc: 0.9726\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0957 - acc: 0.9669\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1054 - acc: 0.9600\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0834 - acc: 0.9611\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1003 - acc: 0.9577\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0870 - acc: 0.9566\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0792 - acc: 0.9600\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0880 - acc: 0.9714\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0817 - acc: 0.9669\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0880 - acc: 0.9657\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0849 - acc: 0.9726\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0672 - acc: 0.9760\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0806 - acc: 0.9680\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0691 - acc: 0.9726\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0752 - acc: 0.9737\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0714 - acc: 0.9646\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0677 - acc: 0.9760\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0509 - acc: 0.9806\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0777 - acc: 0.9703\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0588 - acc: 0.9760\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0685 - acc: 0.9691\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0639 - acc: 0.9771\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0776 - acc: 0.9680\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0542 - acc: 0.9794\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0612 - acc: 0.9794\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0707 - acc: 0.9737\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0499 - acc: 0.9829\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0589 - acc: 0.9794\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0685 - acc: 0.9737\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0641 - acc: 0.9691\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0607 - acc: 0.9806\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.0584 - acc: 0.9794\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.8011 - acc: 0.5851\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6350 - acc: 0.6937\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5861 - acc: 0.7131\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6149 - acc: 0.7109\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5529 - acc: 0.7577\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5135 - acc: 0.7463\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5106 - acc: 0.7646\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5334 - acc: 0.7566\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4599 - acc: 0.7714\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4721 - acc: 0.7840\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4566 - acc: 0.7977\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4550 - acc: 0.7874\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4364 - acc: 0.7954\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4298 - acc: 0.7954\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4146 - acc: 0.8183\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4159 - acc: 0.8149\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3941 - acc: 0.8377\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4048 - acc: 0.8137\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4026 - acc: 0.8251\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4068 - acc: 0.8114\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3566 - acc: 0.8514\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3867 - acc: 0.8206\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3651 - acc: 0.8297\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3766 - acc: 0.8343\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.3469 - acc: 0.8469\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3323 - acc: 0.8400\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3434 - acc: 0.8343\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3629 - acc: 0.8229\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3313 - acc: 0.8480\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3238 - acc: 0.8663\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3024 - acc: 0.8697\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3123 - acc: 0.8617\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.3201 - acc: 0.8549\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3325 - acc: 0.8411\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3210 - acc: 0.8469\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3410 - acc: 0.8423\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3367 - acc: 0.8469\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.3081 - acc: 0.8651\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.3182 - acc: 0.8617\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3210 - acc: 0.8720\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3011 - acc: 0.8651\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3104 - acc: 0.8571\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3159 - acc: 0.8583\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2798 - acc: 0.8834\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3059 - acc: 0.8640\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3031 - acc: 0.8663\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2637 - acc: 0.8811\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2826 - acc: 0.8697\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2669 - acc: 0.8880\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2906 - acc: 0.8537\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.3003 - acc: 0.8571\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2924 - acc: 0.8674\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2616 - acc: 0.8697\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2527 - acc: 0.8834\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2531 - acc: 0.8949\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2886 - acc: 0.8686\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2665 - acc: 0.8754\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2598 - acc: 0.8720\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2758 - acc: 0.8823\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2704 - acc: 0.8903\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2825 - acc: 0.8697\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2640 - acc: 0.8846\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2659 - acc: 0.8857\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2622 - acc: 0.8766\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2419 - acc: 0.8903\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2545 - acc: 0.8811\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2565 - acc: 0.8846\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2329 - acc: 0.9040\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2384 - acc: 0.8891\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2451 - acc: 0.8846\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2629 - acc: 0.8743\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2517 - acc: 0.8720\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2588 - acc: 0.8914\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2310 - acc: 0.8983\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2175 - acc: 0.8811\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2209 - acc: 0.8903\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2217 - acc: 0.9051\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2519 - acc: 0.8869\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2501 - acc: 0.8857\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2273 - acc: 0.8983\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2168 - acc: 0.9074\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2226 - acc: 0.8960\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2151 - acc: 0.9086\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2347 - acc: 0.8937\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2026 - acc: 0.9086\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2273 - acc: 0.8869\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2138 - acc: 0.8960\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2231 - acc: 0.8926\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2129 - acc: 0.8914\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2062 - acc: 0.9086\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2033 - acc: 0.9166\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2255 - acc: 0.8914\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2336 - acc: 0.8789\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2315 - acc: 0.8891\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2278 - acc: 0.8971\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2278 - acc: 0.8869\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2334 - acc: 0.8949\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2291 - acc: 0.8926\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2256 - acc: 0.8869\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.2236 - acc: 0.9040\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7173 - acc: 0.6160\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.6640 - acc: 0.6514\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.6273 - acc: 0.6857\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.6168 - acc: 0.6891\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5807 - acc: 0.7189\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5406 - acc: 0.7383\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5551 - acc: 0.7417\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5567 - acc: 0.7303\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5633 - acc: 0.7360\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5409 - acc: 0.7520\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4831 - acc: 0.7520\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4859 - acc: 0.7783\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4907 - acc: 0.7749\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4867 - acc: 0.7726\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.5033 - acc: 0.7680\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4664 - acc: 0.7646\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4755 - acc: 0.7886\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4412 - acc: 0.7897\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4718 - acc: 0.7840\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4545 - acc: 0.7863\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4392 - acc: 0.7886\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4278 - acc: 0.8114\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4351 - acc: 0.8046\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4605 - acc: 0.7909\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4314 - acc: 0.8011\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4379 - acc: 0.8069\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4252 - acc: 0.8046\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4121 - acc: 0.8137\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4112 - acc: 0.8057\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4255 - acc: 0.8206\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4063 - acc: 0.7989\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4172 - acc: 0.8194\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4319 - acc: 0.8103\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4049 - acc: 0.8206\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4171 - acc: 0.8114\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3963 - acc: 0.8137\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3972 - acc: 0.8126\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3857 - acc: 0.8320\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4074 - acc: 0.8194\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3918 - acc: 0.8217\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4004 - acc: 0.8217\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4129 - acc: 0.7977\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3820 - acc: 0.8354\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3857 - acc: 0.8137\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.4119 - acc: 0.8080\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3961 - acc: 0.8171\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3615 - acc: 0.8320\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3819 - acc: 0.8240\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3790 - acc: 0.8240\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3543 - acc: 0.8286\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3646 - acc: 0.8320\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3676 - acc: 0.8331\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3604 - acc: 0.8389\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3754 - acc: 0.8320\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3863 - acc: 0.8331\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3410 - acc: 0.8377\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3739 - acc: 0.8251\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3504 - acc: 0.8400\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3438 - acc: 0.8491\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3263 - acc: 0.8537\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3301 - acc: 0.8331\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3422 - acc: 0.8480\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 2s 3ms/step - loss: 0.3408 - acc: 0.8537\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 2s 3ms/step - loss: 0.3778 - acc: 0.8343\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3546 - acc: 0.8503\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3390 - acc: 0.8423\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3657 - acc: 0.8297\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3453 - acc: 0.8480\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3468 - acc: 0.8434\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3116 - acc: 0.8617\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3349 - acc: 0.8411\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3335 - acc: 0.8469\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3263 - acc: 0.8629\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3644 - acc: 0.8331\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3519 - acc: 0.8400\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3302 - acc: 0.8514\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3262 - acc: 0.8480\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.2965 - acc: 0.8720\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3273 - acc: 0.8480\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.2985 - acc: 0.8789\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3147 - acc: 0.8629\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3073 - acc: 0.8640\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3182 - acc: 0.8663\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3153 - acc: 0.8583\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3118 - acc: 0.8583\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3018 - acc: 0.8606\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3376 - acc: 0.8514\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3117 - acc: 0.8514\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3136 - acc: 0.8686\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3317 - acc: 0.8526\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3012 - acc: 0.8697\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3685 - acc: 0.8343\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.2833 - acc: 0.8823\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.2995 - acc: 0.8640\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3101 - acc: 0.8583\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.2987 - acc: 0.8617\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.2992 - acc: 0.8629\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.3031 - acc: 0.8754\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.2890 - acc: 0.8686\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 3s 3ms/step - loss: 0.2955 - acc: 0.8811\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 10s 11ms/step - loss: 0.7369 - acc: 0.6366\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5692 - acc: 0.7120\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5372 - acc: 0.7520\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5638 - acc: 0.7360\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5319 - acc: 0.7691\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5255 - acc: 0.7486\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.5440 - acc: 0.7623\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4953 - acc: 0.7646\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4563 - acc: 0.7920\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.4610 - acc: 0.7943\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.4010 - acc: 0.8217\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.4414 - acc: 0.8069\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.4101 - acc: 0.8080\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.4292 - acc: 0.8057\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.4103 - acc: 0.8114\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.4076 - acc: 0.8240\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.4334 - acc: 0.8114\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3853 - acc: 0.8297\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3605 - acc: 0.8434\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3654 - acc: 0.8286\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.3603 - acc: 0.8423\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3500 - acc: 0.8411\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3449 - acc: 0.8503\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3505 - acc: 0.8274\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3564 - acc: 0.8469\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3485 - acc: 0.8549\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3594 - acc: 0.8423\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3482 - acc: 0.8354\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3059 - acc: 0.8663\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3241 - acc: 0.8560\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3280 - acc: 0.8640\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2989 - acc: 0.8537\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2747 - acc: 0.8731\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3076 - acc: 0.8617\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.3089 - acc: 0.8674\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2835 - acc: 0.8766\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2671 - acc: 0.8823\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 7s 8ms/step - loss: 0.2685 - acc: 0.8766\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2832 - acc: 0.8606\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2488 - acc: 0.8914\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2673 - acc: 0.8823\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2593 - acc: 0.8800\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2869 - acc: 0.8697\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2690 - acc: 0.8697\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2773 - acc: 0.8766\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2599 - acc: 0.8971\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2422 - acc: 0.8926\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2492 - acc: 0.8846\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2457 - acc: 0.8937\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2695 - acc: 0.8789\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2699 - acc: 0.8766\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2558 - acc: 0.8857\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2357 - acc: 0.8914\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2729 - acc: 0.8823\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2665 - acc: 0.8709\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2466 - acc: 0.8891\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2564 - acc: 0.8846\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2488 - acc: 0.8869\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2188 - acc: 0.8960\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2351 - acc: 0.9017\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1987 - acc: 0.9074\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2391 - acc: 0.8891\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2285 - acc: 0.8903\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2090 - acc: 0.9029\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2337 - acc: 0.8971\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2565 - acc: 0.8857\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2428 - acc: 0.8869\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2224 - acc: 0.9029\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2256 - acc: 0.8983\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2064 - acc: 0.9154\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2109 - acc: 0.9006\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2182 - acc: 0.9131\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2601 - acc: 0.8800\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2561 - acc: 0.8937\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2015 - acc: 0.9051\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2073 - acc: 0.9029\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2160 - acc: 0.8949\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2415 - acc: 0.8994\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2090 - acc: 0.8914\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2126 - acc: 0.8983\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1836 - acc: 0.9234\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2163 - acc: 0.8971\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2216 - acc: 0.9006\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2405 - acc: 0.8891\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1996 - acc: 0.9074\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2045 - acc: 0.9040\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1912 - acc: 0.9189\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2235 - acc: 0.8994\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1684 - acc: 0.9177\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2126 - acc: 0.8926\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1972 - acc: 0.9086\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2242 - acc: 0.8971\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2146 - acc: 0.9051\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1900 - acc: 0.9143\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2012 - acc: 0.8983\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1999 - acc: 0.9006\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1894 - acc: 0.9177\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2222 - acc: 0.9029\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.1759 - acc: 0.9120\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.2021 - acc: 0.9074\n",
      "Epoch 1/100\n",
      "875/875 [==============================] - 18s 20ms/step - loss: 0.7412 - acc: 0.5520\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.6175 - acc: 0.6663\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5964 - acc: 0.6686\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5617 - acc: 0.7109\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5463 - acc: 0.7371\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5200 - acc: 0.7314\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5308 - acc: 0.7497\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.5183 - acc: 0.7486\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4967 - acc: 0.7600\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4933 - acc: 0.7646\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4950 - acc: 0.7749\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4591 - acc: 0.7806\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4619 - acc: 0.7863\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4809 - acc: 0.7794\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4502 - acc: 0.7954\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4430 - acc: 0.8069\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4579 - acc: 0.7909\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4160 - acc: 0.8103\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4401 - acc: 0.7954\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4218 - acc: 0.8057\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4326 - acc: 0.8103\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.3959 - acc: 0.8434\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4127 - acc: 0.8091\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4161 - acc: 0.8229\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4219 - acc: 0.8103\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 13s 15ms/step - loss: 0.4118 - acc: 0.8183\n",
      "Epoch 27/100\n",
      "864/875 [============================>.] - ETA: 0s - loss: 0.4226 - acc: 0.8090"
     ]
    }
   ],
   "source": [
    "X_RawECG       = np.array( RawEcgScan )\n",
    "X_LeadII       = np.array( LeadIIEcgScan)\n",
    "\n",
    "for (raw_ecg_scan_length, lead_2_scan_length) in scanLength:\n",
    "    \n",
    "    logger = open('model_perf_loggger.txt', 'a')\n",
    "    \n",
    "    \n",
    "    raw_ecg_scan_length = raw_ecg_scan_length * 250\n",
    "    noOfEpochs = 100\n",
    "    trainValPercent = 0.8\n",
    "    \n",
    "    validation_split_percent = 0.0\n",
    "\n",
    "    X_RawECG_pad = sequence.pad_sequences(X_RawECG, maxlen=raw_ecg_scan_length)\n",
    "    X_LeadII_pad = sequence.pad_sequences(X_LeadII, maxlen=lead_2_scan_length)\n",
    "    \n",
    "    Y = np.array(scanTypesInt)\n",
    "    totSamples = X_RawECG.shape[0]\n",
    "    shuffleIdxs = list (range(0,totSamples))\n",
    "    random.shuffle( shuffleIdxs  )\n",
    "    X_RawECG_train = X_RawECG_pad[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ],  ]\n",
    "    X_RawECG_test  = X_RawECG_pad[ shuffleIdxs[ int(trainValPercent * totSamples) :   ],  ]\n",
    "    X_LeadII_train = X_LeadII_pad[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ],  ]\n",
    "    X_LeadII_test  = X_LeadII_pad[ shuffleIdxs[ int(trainValPercent * totSamples) :   ],  ]\n",
    "\n",
    "\n",
    "    Y_train = Y[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ]   ]\n",
    "    Y_test  = Y[ shuffleIdxs[ int(trainValPercent * totSamples) :   ]   ]\n",
    "\n",
    "\n",
    "    X_RawECG_train.shape, X_RawECG_test.shape,X_LeadII_train.shape, X_LeadII_test.shape, Y_train.shape, Y_test.shape\n",
    "\n",
    "    \n",
    "    logger.write('raw_ecg_scan_length: {}, lead_2_scan_length: {}'.format(raw_ecg_scan_length, lead_2_scan_length) + '\\n')\n",
    "    \n",
    "    \n",
    "    lead_2_input_data  = layers.Input(shape=(lead_2_scan_length, 14))\n",
    "    raw_ecg_input_data = layers.Input(shape=(raw_ecg_scan_length, 12))\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('lead_2_model', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                   verbose = 1, save_best_only=True)    \n",
    "    logger.write('    lead_2_input_data model is getting build' + '\\n')\n",
    "    lead_2_model = lead2Model(lead_2_input_data)\n",
    "    lead_2_model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    lead_2_model_history=lead_2_model.fit(X_LeadII_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                          validation_split=validation_split_percent,\n",
    "                                          callbacks=[checkpointer])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('rawecg_lead2_convseparableModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                   verbose = 1, save_best_only=True)\n",
    "    logger.write('    rawecg_lead2_convseparableModel is getting build' + '\\n')\n",
    "    rawecg_lead2_convseparableModel = rawecg_lead2_convseparable(lead_2_input_data, raw_ecg_input_data)\n",
    "    rawecg_lead2_convseparableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    rawecg_lead2_convseparableModel_history=rawecg_lead2_convseparableModel.fit(\n",
    "            [X_LeadII_train, X_RawECG_train], Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "            validation_split=validation_split_percent,\n",
    "            callbacks=[checkpointer]\n",
    "    )\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('convolutioModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                   verbose = 1, save_best_only=True)    \n",
    "    logger.write('    convolutioModel is getting build' + '\\n')\n",
    "    convolutioModel = baseModel_Conv1D(raw_ecg_input_data)\n",
    "    convolutioModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    conv_history=convolutioModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                     validation_split=validation_split_percent,\n",
    "                                     callbacks=[checkpointer]\n",
    "                                    )\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('separableModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                   verbose = 1, save_best_only=True)    \n",
    "    logger.write('    separableModel is getting build' + '\\n')\n",
    "    separableModel = baseModel_Separable1D(raw_ecg_input_data)\n",
    "    separableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    separableconv_history = separableModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                               validation_split=validation_split_percent, \n",
    "                                               callbacks=[checkpointer])\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('convSeparableModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                   verbose = 1, save_best_only=True)    \n",
    "    convSeparableModel = convSeparable(raw_ecg_input_data)\n",
    "    logger.write('    convSeparableModel is getting build' + '\\n')\n",
    "    convSeparableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    separableconv_history = convSeparableModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                                   validation_split=validation_split_percent, \n",
    "                                                   callbacks=[checkpointer])\n",
    "\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('ConvGRUWithStridesModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                   verbose = 1, save_best_only=True)\n",
    "    logger.write('    ConvGRUWithStridesModel is getting build' + '\\n')\n",
    "    ConvGRUWithStridesModel = baseModel_ConvGRUWithStrides(raw_ecg_input_data)\n",
    "    ConvGRUWithStridesModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    ConvGRUWithStridesModel_history = ConvGRUWithStridesModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                                                 validation_split=validation_split_percent, \n",
    "                                                                 callbacks=[checkpointer])\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('SeparableConvGRUWithStridesModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                   verbose = 1, save_best_only=True)    \n",
    "    logger.write('    SeparableConvGRUWithStridesModel is getting build' + '\\n')\n",
    "    SeparableConvGRUWithStridesModel = baseModel_SeparableConvGRUWithStrides(raw_ecg_input_data)\n",
    "    SeparableConvGRUWithStridesModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    SeparableConvGRUWithStridesModel_history = SeparableConvGRUWithStridesModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                                                                    validation_split=validation_split_percent, \n",
    "                                                                                   callbacks=[checkpointer])\n",
    "\n",
    "        \n",
    "    lead_2_model_test_accuracy = round( 100*lead_2_model.evaluate(X_LeadII_test, Y_test, verbose=2)[1], 10 ) \n",
    "    rawecg_lead2_convseparableModel_test_accuracy = round( 100*rawecg_lead2_convseparableModel.evaluate([X_LeadII_test, X_RawECG_test], Y_test, verbose=2)[1], 10) \n",
    "    convolutioModel_test_accuracy = round( 100*convolutioModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "    separableModel_test_accuracy  = round( 100*separableModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "    convSeparableModel_test_accuracy = round( 100*convSeparableModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "    ConvGRUWithStridesModel_test_accuracy = round( 100*ConvGRUWithStridesModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "    SeparableConvGRUWithStridesModel_test_accuracy = round( 100*SeparableConvGRUWithStridesModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "    \n",
    "    logger.write('    lead_2_model_test_accuracy: {}'.format(lead_2_model_test_accuracy)+'\\n')\n",
    "    logger.write('    rawecg_lead2_convseparableModel_test_accuracy: {}'.format(rawecg_lead2_convseparableModel_test_accuracy)+'\\n')\n",
    "    logger.write('    convolutioModel_test_accuracy: {}'.format(convolutioModel_test_accuracy)+'\\n')\n",
    "    logger.write('    separableModel_test_accuracy: {}'.format(separableModel_test_accuracy)+'\\n')\n",
    "    logger.write('    convSeparableModel_test_accuracy: {}'.format(convSeparableModel_test_accuracy)+'\\n')\n",
    "    logger.write('    ConvGRUWithStridesModel_test_accuracy: {}'.format(ConvGRUWithStridesModel_test_accuracy)+'\\n')\n",
    "    logger.write('    SeparableConvGRUWithStridesModel_test_accuracy: {}'.format(SeparableConvGRUWithStridesModel_test_accuracy)+'\\n')\n",
    "    \n",
    "    listOfBaseModels = [\n",
    "        lead_2_model,\n",
    "        convolutioModel,\n",
    "        separableModel,\n",
    "        convSeparableModel,\n",
    "        ConvGRUWithStridesModel,\n",
    "        SeparableConvGRUWithStridesModel,\n",
    "        rawecg_lead2_convseparableModel\n",
    "    ]\n",
    "    ensemle_model_allmodels = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "    ensemle_model_allmodels_test_accuracy =  100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model_allmodels.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test )  / Y_test.shape[0]\n",
    "    logger.write('    ensemle_model_allmodels_test_accuracy: {}'.format(ensemle_model_allmodels_test_accuracy)+'\\n')\n",
    "    \n",
    "    \n",
    "    listOfBaseModels = [\n",
    "        lead_2_model,\n",
    "        convSeparableModel,\n",
    "        ConvGRUWithStridesModel,\n",
    "        rawecg_lead2_convseparableModel\n",
    "    ]\n",
    "    \n",
    "    ensemle_model_fourmodels = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "    ensemle_model_fourmodels_test_accuracy =  100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model_fourmodels.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test )  / Y_test.shape[0]\n",
    "    logger.write('    ensemle_model_fourmodels_test_accuracy(lead_2_model, convSeparableModel, ConvGRUWithStridesModel, rawecg_lead2_convseparableModel): {}'.format(ensemle_model_fourmodels_test_accuracy)+'\\n')\n",
    "      \n",
    "    listOfBaseModels = [\n",
    "        lead_2_model,\n",
    "        convolutioModel,\n",
    "        separableModel,\n",
    "        convSeparableModel,\n",
    "        ConvGRUWithStridesModel,\n",
    "        rawecg_lead2_convseparableModel\n",
    "    ]\n",
    "    \n",
    "    ensemle_model_sixmodels = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "    ensemle_model_sixmodels_test_accuracy =  100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model_sixmodels.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test )  / Y_test.shape[0]\n",
    "    logger.write('    ensemle_model_sixmodels_test_accuracy(lead_2_model, convolutioModel, separableModel, convSeparableModel, ConvGRUWithStridesModel, rawecg_lead2_convseparableModel): {}'.format(ensemle_model_sixmodels_test_accuracy)+'\\n')\n",
    "      \n",
    "        \n",
    "    logger.close()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead2Model(model_input):\n",
    "    \n",
    "    lead_2_input_data_batchnormalized  = layers.BatchNormalization()(model_input)\n",
    "    \n",
    "    lead_2_branch = layers.Conv1D(32,  5, activation='relu')(lead_2_input_data_batchnormalized)\n",
    "    lead_2_branch = layers.Conv1D(64,  3, activation='relu')(lead_2_branch)\n",
    "    lead_2_branch = layers.Conv1D(128, 1, activation='relu')(lead_2_branch)\n",
    "    lead_2_branch = layers.Flatten()(lead_2_branch)\n",
    "    \n",
    "    predictions = layers.Dense(1, activation='sigmoid')(lead_2_branch)\n",
    "    model = Model(inputs=model_input, outputs=predictions)\n",
    "    \n",
    "    return model;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875, 1250, 12) (219, 1250, 12) (875, 10, 14) (219, 10, 14) (875,) (219,)\n",
      "raw_ecg_scan_length: 1250, lead_2_scan_length: 10\n",
      "\n",
      "    lead_2_input_data model is getting build\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:435: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rawecg_lead2_convseparableModel is getting build\n",
      "\n",
      "    convSeparableModel is getting build\n",
      "\n",
      "  ConvGRUWithStridesModel is getting build\n",
      "\n",
      "    lead_2_model_test_accuracy: 79.4520546857\n",
      "\n",
      "    rawecg_lead2_convseparableModel_test_accuracy: 87.214612226\n",
      "\n",
      "    convSeparableModel_test_accuracy: 83.1050229944\n",
      "\n",
      "    ConvGRUWithStridesModel_test_accuracy: 78.9954339533\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ensembleWithAverage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-623efe1d2750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m         ]\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mensemle_model_fourmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensembleWithAverage\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlead_2_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_ecg_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistOfBaseModels\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mensemle_model_fourmodels_test_accuracy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mval_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mensemle_model_fourmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_LeadII_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_RawECG_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.5\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'    ensemle_model_fourmodels_test_accuracy(lead_2_model, convSeparableModel, ConvGRUWithStridesModel, rawecg_lead2_convseparableModel): {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemle_model_fourmodels_test_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ensembleWithAverage' is not defined"
     ]
    }
   ],
   "source": [
    "scanLength = [ (5,10) ]\n",
    "for i in range(10):\n",
    "    for (raw_ecg_scan_length, lead_2_scan_length) in scanLength:\n",
    "\n",
    "        \n",
    "\n",
    "        raw_ecg_scan_length = raw_ecg_scan_length * 250\n",
    "        noOfEpochs = 100\n",
    "        trainValPercent = 0.8\n",
    "\n",
    "        validation_split_percent = 0.0\n",
    "\n",
    "        X_RawECG_pad = sequence.pad_sequences(X_RawECG, maxlen=raw_ecg_scan_length)\n",
    "        X_LeadII_pad = sequence.pad_sequences(X_LeadII, maxlen=lead_2_scan_length)\n",
    "\n",
    "        Y = np.array(scanTypesInt)\n",
    "        totSamples = X_RawECG.shape[0]\n",
    "        shuffleIdxs = list (range(0,totSamples))\n",
    "        random.shuffle( shuffleIdxs  )\n",
    "        X_RawECG_train = X_RawECG_pad[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ],  ]\n",
    "        X_RawECG_test  = X_RawECG_pad[ shuffleIdxs[ int(trainValPercent * totSamples) :   ],  ]\n",
    "        X_LeadII_train = X_LeadII_pad[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ],  ]\n",
    "        X_LeadII_test  = X_LeadII_pad[ shuffleIdxs[ int(trainValPercent * totSamples) :   ],  ]\n",
    "\n",
    "\n",
    "        Y_train = Y[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ]   ]\n",
    "        Y_test  = Y[ shuffleIdxs[ int(trainValPercent * totSamples) :   ]   ]\n",
    "\n",
    "\n",
    "        print(X_RawECG_train.shape, X_RawECG_test.shape,X_LeadII_train.shape, X_LeadII_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "\n",
    "        print('raw_ecg_scan_length: {}, lead_2_scan_length: {}'.format(raw_ecg_scan_length, lead_2_scan_length) + '\\n')\n",
    "\n",
    "\n",
    "        lead_2_input_data  = layers.Input(shape=(lead_2_scan_length, 14))\n",
    "        raw_ecg_input_data = layers.Input(shape=(raw_ecg_scan_length, 12))\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('lead_2_model', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                       verbose = 1, save_best_only=True)    \n",
    "        print('    lead_2_input_data model is getting build' + '\\n')\n",
    "        lead_2_model = lead2Model(lead_2_input_data)\n",
    "        lead_2_model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "        lead_2_model_history=lead_2_model.fit(X_LeadII_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                              validation_split=validation_split_percent,\n",
    "                                              callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('rawecg_lead2_convseparableModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                       verbose = 1, save_best_only=True)\n",
    "        print('    rawecg_lead2_convseparableModel is getting build' + '\\n')\n",
    "        rawecg_lead2_convseparableModel = rawecg_lead2_convseparable(lead_2_input_data, raw_ecg_input_data)\n",
    "        rawecg_lead2_convseparableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "        rawecg_lead2_convseparableModel_history=rawecg_lead2_convseparableModel.fit(\n",
    "                [X_LeadII_train, X_RawECG_train], Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                validation_split=validation_split_percent,\n",
    "                callbacks=[checkpointer], verbose=0\n",
    "        )\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('convSeparableModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                       verbose = 1, save_best_only=True)    \n",
    "        convSeparableModel = convSeparable(raw_ecg_input_data)\n",
    "        print('    convSeparableModel is getting build' + '\\n')\n",
    "        convSeparableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "        separableconv_history = convSeparableModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                                       validation_split=validation_split_percent, \n",
    "                                                       callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('ConvGRUWithStridesModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                       verbose = 1, save_best_only=True)\n",
    "        print('  ConvGRUWithStridesModel is getting build' + '\\n')\n",
    "        ConvGRUWithStridesModel = baseModel_ConvGRUWithStrides(raw_ecg_input_data)\n",
    "        ConvGRUWithStridesModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "        ConvGRUWithStridesModel_history = ConvGRUWithStridesModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                                                     validation_split=validation_split_percent, \n",
    "                                                                     callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "\n",
    "                \n",
    "        lead_2_model_test_accuracy = round( 100*lead_2_model.evaluate(X_LeadII_test, Y_test, verbose=2)[1], 10 ) \n",
    "        rawecg_lead2_convseparableModel_test_accuracy = round( 100*rawecg_lead2_convseparableModel.evaluate([X_LeadII_test, X_RawECG_test], Y_test, verbose=2)[1], 10) \n",
    "        convSeparableModel_test_accuracy = round( 100*convSeparableModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "        ConvGRUWithStridesModel_test_accuracy = round( 100*ConvGRUWithStridesModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "       \n",
    "        logger.write('    lead_2_model_test_accuracy: {}'.format(lead_2_model_test_accuracy)+'\\n')\n",
    "        logger.write('    rawecg_lead2_convseparableModel_test_accuracy: {}'.format(rawecg_lead2_convseparableModel_test_accuracy)+'\\n')       \n",
    "        logger.write('    convSeparableModel_test_accuracy: {}'.format(convSeparableModel_test_accuracy)+'\\n')\n",
    "        logger.write('    ConvGRUWithStridesModel_test_accuracy: {}'.format(ConvGRUWithStridesModel_test_accuracy)+'\\n')\n",
    "\n",
    "\n",
    "        listOfBaseModels = [\n",
    "            lead_2_model,\n",
    "            convSeparableModel,\n",
    "            ConvGRUWithStridesModel,\n",
    "            rawecg_lead2_convseparableModel\n",
    "        ]\n",
    "\n",
    "        ensemle_model_fourmodels = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "        ensemle_model_fourmodels_test_accuracy =  100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model_fourmodels.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test )  / Y_test.shape[0]\n",
    "        logger.write('    ensemle_model_fourmodels_test_accuracy(lead_2_model, convSeparableModel, ConvGRUWithStridesModel, rawecg_lead2_convseparableModel): {}'.format(ensemle_model_fourmodels_test_accuracy)+'\\n')\n",
    "\n",
    "        logger.close()        \n",
    "        lead_2_model_test_accuracy = round( 100*lead_2_model.evaluate(X_LeadII_test, Y_test, verbose=2)[1], 10 ) \n",
    "        rawecg_lead2_convseparableModel_test_accuracy = round( 100*rawecg_lead2_convseparableModel.evaluate([X_LeadII_test, X_RawECG_test], Y_test, verbose=2)[1], 10) \n",
    "        convSeparableModel_test_accuracy = round( 100*convSeparableModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "        ConvGRUWithStridesModel_test_accuracy = round( 100*ConvGRUWithStridesModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "       \n",
    "        logger.write('    lead_2_model_test_accuracy: {}'.format(lead_2_model_test_accuracy)+'\\n')\n",
    "        logger.write('    rawecg_lead2_convseparableModel_test_accuracy: {}'.format(rawecg_lead2_convseparableModel_test_accuracy)+'\\n')       \n",
    "        logger.write('    convSeparableModel_test_accuracy: {}'.format(convSeparableModel_test_accuracy)+'\\n')\n",
    "        logger.write('    ConvGRUWithStridesModel_test_accuracy: {}'.format(ConvGRUWithStridesModel_test_accuracy)+'\\n')\n",
    "\n",
    "\n",
    "        listOfBaseModels = [\n",
    "            lead_2_model,\n",
    "            convSeparableModel,\n",
    "            ConvGRUWithStridesModel,\n",
    "            rawecg_lead2_convseparableModel\n",
    "        ]\n",
    "\n",
    "        ensemle_model_fourmodels = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "        ensemle_model_fourmodels_test_accuracy =  100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model_fourmodels.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test )  / Y_test.shape[0]\n",
    "        logger.write('    ensemle_model_fourmodels_test_accuracy(lead_2_model, convSeparableModel, ConvGRUWithStridesModel, rawecg_lead2_convseparableModel): {}'.format(ensemle_model_fourmodels_test_accuracy)+'\\n')\n",
    "\n",
    "        logger.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ensemle_model_fourmodels_test_accuracy(lead_2_model, convSeparableModel, ConvGRUWithStridesModel, rawecg_lead2_convseparableModel): 86.7579908675799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listOfBaseModels = [\n",
    "            lead_2_model,\n",
    "            convSeparableModel,\n",
    "            ConvGRUWithStridesModel,\n",
    "            rawecg_lead2_convseparableModel\n",
    "        ]\n",
    "\n",
    "ensemle_model_fourmodels = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "ensemle_model_fourmodels_test_accuracy =  100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model_fourmodels.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test )  / Y_test.shape[0]\n",
    "print('    ensemle_model_fourmodels_test_accuracy(lead_2_model, convSeparableModel, ConvGRUWithStridesModel, rawecg_lead2_convseparableModel): {}'.format(ensemle_model_fourmodels_test_accuracy)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanLength = [\n",
    "    (5,50),\n",
    "    (5,100),\n",
    "    (10,50),\n",
    "    (10,100),\n",
    "    (20,50),\n",
    "    (20,100),\n",
    "   \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_RawECG       = np.array( RawEcgScan )\n",
    "X_LeadII       = np.array( LeadIIEcgScan)\n",
    "\n",
    "for (raw_ecg_scan_length, lead_2_scan_length) in scanLength:\n",
    "\n",
    "    raw_ecg_scan_length = raw_ecg_scan_length * 250\n",
    "    noOfEpochs = 100\n",
    "    trainValPercent = 0.8\n",
    "\n",
    "    validation_split_percent = 0.0\n",
    "        \n",
    "    for eachRun in range(5):\n",
    "        \n",
    "        \n",
    "    \n",
    "        logger = open('model_perf_loggger_{}_{}.txt'.format(raw_ecg_scan_length,lead_2_scan_length), 'a')\n",
    "        \n",
    "        X_RawECG_pad = sequence.pad_sequences(X_RawECG, maxlen=raw_ecg_scan_length)\n",
    "        X_LeadII_pad = sequence.pad_sequences(X_LeadII, maxlen=lead_2_scan_length)\n",
    "\n",
    "        Y = np.array(scanTypesInt)\n",
    "        totSamples = X_RawECG.shape[0]\n",
    "        shuffleIdxs = list (range(0,totSamples))\n",
    "        random.shuffle( shuffleIdxs  )\n",
    "        X_RawECG_train = X_RawECG_pad[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ],  ]\n",
    "        X_RawECG_test  = X_RawECG_pad[ shuffleIdxs[ int(trainValPercent * totSamples) :   ],  ]\n",
    "        X_LeadII_train = X_LeadII_pad[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ],  ]\n",
    "        X_LeadII_test  = X_LeadII_pad[ shuffleIdxs[ int(trainValPercent * totSamples) :   ],  ]\n",
    "\n",
    "\n",
    "        Y_train = Y[ shuffleIdxs[ 0 : int(trainValPercent * totSamples) ]   ]\n",
    "        Y_test  = Y[ shuffleIdxs[ int(trainValPercent * totSamples) :   ]   ]\n",
    "\n",
    "\n",
    "        X_RawECG_train.shape, X_RawECG_test.shape,X_LeadII_train.shape, X_LeadII_test.shape, Y_train.shape, Y_test.shape\n",
    "\n",
    "\n",
    "        logger.write('raw_ecg_scan_length: {}, lead_2_scan_length: {}'.format(raw_ecg_scan_length, lead_2_scan_length) + '\\n')\n",
    "\n",
    "\n",
    "        lead_2_input_data  = layers.Input(shape=(lead_2_scan_length, 14))\n",
    "        raw_ecg_input_data = layers.Input(shape=(raw_ecg_scan_length, 12))\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('lead_2_model', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                       verbose = 1, save_best_only=True)    \n",
    "        logger.write('    lead_2_input_data model is getting build' + '\\n')\n",
    "        lead_2_model = lead2Model(lead_2_input_data)\n",
    "        lead_2_model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "        lead_2_model_history=lead_2_model.fit(X_LeadII_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                              validation_split=validation_split_percent,\n",
    "                                              callbacks=[checkpointer])\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('rawecg_lead2_convseparableModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                       verbose = 1, save_best_only=True)\n",
    "        logger.write('    rawecg_lead2_convseparableModel is getting build' + '\\n')\n",
    "        rawecg_lead2_convseparableModel = rawecg_lead2_convseparable(lead_2_input_data, raw_ecg_input_data)\n",
    "        rawecg_lead2_convseparableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "        rawecg_lead2_convseparableModel_history=rawecg_lead2_convseparableModel.fit(\n",
    "                [X_LeadII_train, X_RawECG_train], Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                validation_split=validation_split_percent,\n",
    "                callbacks=[checkpointer]\n",
    "        )\n",
    "\n",
    "        \n",
    "        checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('convSeparableModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                       verbose = 1, save_best_only=True)    \n",
    "        convSeparableModel = convSeparable(raw_ecg_input_data)\n",
    "        logger.write('    convSeparableModel is getting build' + '\\n')\n",
    "        convSeparableModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "        separableconv_history = convSeparableModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                                       validation_split=validation_split_percent, \n",
    "                                                       callbacks=[checkpointer])\n",
    "\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath='{}.model.weights.best.{}_{}.hdf5'.format('ConvGRUWithStridesModel', raw_ecg_scan_length,lead_2_scan_length ), \n",
    "                                       verbose = 1, save_best_only=True)\n",
    "        logger.write('    ConvGRUWithStridesModel is getting build' + '\\n')\n",
    "        ConvGRUWithStridesModel = baseModel_ConvGRUWithStrides(raw_ecg_input_data)\n",
    "        ConvGRUWithStridesModel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "        ConvGRUWithStridesModel_history = ConvGRUWithStridesModel.fit(X_RawECG_train, Y_train, epochs=noOfEpochs, batch_size=32, \n",
    "                                                                     validation_split=validation_split_percent, \n",
    "                                                                     callbacks=[checkpointer])\n",
    "\n",
    "        lead_2_model_test_accuracy = round( 100*lead_2_model.evaluate(X_LeadII_test, Y_test, verbose=2)[1], 10 ) \n",
    "        rawecg_lead2_convseparableModel_test_accuracy = round( 100*rawecg_lead2_convseparableModel.evaluate([X_LeadII_test, X_RawECG_test], Y_test, verbose=2)[1], 10) \n",
    "        convSeparableModel_test_accuracy = round( 100*convSeparableModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "        ConvGRUWithStridesModel_test_accuracy = round( 100*ConvGRUWithStridesModel.evaluate(X_RawECG_test, Y_test, verbose=2)[1], 10) \n",
    "        \n",
    "        logger.write('    lead_2_model_test_accuracy: {}'.format(lead_2_model_test_accuracy)+'\\n')\n",
    "        logger.write('    rawecg_lead2_convseparableModel_test_accuracy: {}'.format(rawecg_lead2_convseparableModel_test_accuracy)+'\\n')\n",
    "        logger.write('    convSeparableModel_test_accuracy: {}'.format(convSeparableModel_test_accuracy)+'\\n')\n",
    "        logger.write('    ConvGRUWithStridesModel_test_accuracy: {}'.format(ConvGRUWithStridesModel_test_accuracy)+'\\n')\n",
    "        \n",
    "        listOfBaseModels = [\n",
    "            lead_2_model,\n",
    "            convSeparableModel,\n",
    "            ConvGRUWithStridesModel,\n",
    "            rawecg_lead2_convseparableModel\n",
    "        ]\n",
    "\n",
    "        ensemle_model_fourmodels = ensembleWithAverage( [lead_2_input_data, raw_ecg_input_data], listOfBaseModels )\n",
    "        ensemle_model_fourmodels_test_accuracy =  100 * np.sum ( np.array( [ 1 if val_ else 0 for val_ in ensemle_model_fourmodels.predict([X_LeadII_test, X_RawECG_test])[:,0] > .5 ] ) == Y_test )  / Y_test.shape[0]\n",
    "        logger.write('    ensemle_model_fourmodels_test_accuracy(lead_2_model, convSeparableModel, ConvGRUWithStridesModel, rawecg_lead2_convseparableModel): {}'.format(ensemle_model_fourmodels_test_accuracy)+'\\n')\n",
    "        logger.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
